<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[我的技能树]]></title>
    <url>%2F2017%2F03%2F01%2Fskill_tree%2F</url>
    <content type="text"><![CDATA[以下为我的技能树: 请 在新标签页中打开链接 后放大观看 ^_^]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RPC框架]]></title>
    <url>%2F2017%2F02%2F24%2Frpc_framework%2F</url>
    <content type="text"><![CDATA[此RPC框架实现了基本的RPC通信及服务注册/发现功能。 基本原理如下: 代码详见: rpc Techs此RPC框架依赖于以下技术: Spring: 依赖注入 Netty: NIO Server Protostuff: RPC通讯过程中的序列化/反序列化 Zookeeper: 服务注册与发现 主要是使用Netty构建server，同时在服务启动时向ZK注册服务serviceAddress, servicePort等信息。使用client发送请求时，将请求动态代理成对netty server的请求。server和client的通讯使用protostuff进行编码和解码。 Modules rpc-client: RPC client实现 RpcClient: RPC客户端 RpcProxy: RPC代理，用于创建RPC请求动态代理对象 rpc-common bean RpcRequest: RPC请求结构体 RpcResponse: RPC响应结构体 codec RpcDecoder: RPC通信解码 RpcEncoder: RPC通信编码 util CollectionUtil: 集合工具类 SerializationUtil: 序列化/反序列化工具类 StringUtil: 字符串工具类 rpc-registry: 服务注册和发现接口 ServiceDiscovery: 服务发现接口 ServiceRegistry: 服务注册接口 rpc-registry-zookeeper: 基于zk的服务注册和发现 ZooKeeperServiceDiscovery: 基于zk的服务发现实现 ZooKeeperServiceRegistry: 基于zk的服务注册实现 rpc-sample: RPC框架的使用代码示例 rpc-sample-api: RPC接口定义 rpc-sample-demo: RPC请求client Demo rpc-sample-service: RPC接口实现 rpc-server: RPC server实现 RpcServer: RPC服务器 RpcServerHandler: RPC请求处理 RpcService: RPC服务注解 Usage以下为使用步骤，代码实现在rpc-sample中。 1. 定义接口12345public interface HelloService &#123; String hello(String name);&#125; 2. 实现接口123456789@RpcService(HelloService.class)public class HelloServiceImpl implements HelloService &#123; @Override public String hello(String name) &#123; return &quot;Hello! &quot; + name; &#125;&#125; 3. 配置并启动RPC服务123456789public class RpcBootstrap &#123; private static final Logger LOGGER = LoggerFactory.getLogger(RpcBootstrap.class); public static void main(String[] args) &#123; LOGGER.debug(&quot;start service&quot;); new ClassPathXmlApplicationContext(&quot;spring.xml&quot;); &#125;&#125; spring.xml中的配置含义如下: rpc.service_address: RPC服务地址 rpc.registry_address: RPC服务注册地址 启动日志如下: 1234567start serviceconnect zookeepercreate registry node: /registrycreate service node: /registry/joshuahw.sample.api.HelloServicecreate address node: /registry/joshuahw.sample.api.HelloService/address-0000000000register service: joshuahw.sample.api.HelloService =&gt; 127.0.0.1:2017server started on port 2017 4. 配置并调用RPC服务使用RpcProxy创建对应接口的代理。将对接口方法的调用，动态代理成对RPC server(Netty Server)的请求。 1234567891011121314public class HelloClient &#123; public static void main(String[] args) throws Exception &#123; ApplicationContext context = new ClassPathXmlApplicationContext(&quot;spring.xml&quot;); RpcProxy rpcProxy = context.getBean(RpcProxy.class); HelloService helloService = rpcProxy.create(HelloService.class); String result = helloService.hello(&quot;Joshua&quot;); System.out.println(result); System.exit(0); &#125;&#125; 调用日志如下: 12345connect zookeeperget only address node: address-0000000000discover service: joshuahw.sample.api.HelloService =&gt; 127.0.0.1:2017time: 400msHello! Joshua]]></content>
      <categories>
        <category>arch</category>
      </categories>
      <tags>
        <tag>arch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RPC框架 & 服务治理]]></title>
    <url>%2F2017%2F02%2F04%2Frpc%2F</url>
    <content type="text"><![CDATA[RPC框架概念RPC，即远程过程调用，说得通俗一点就是：调用远程计算机上的服务，就像调用本地服务一样。RPC框架是SOA架构的重要基石。 IO模型衡量一个RPC框架性能的好坏与否，RPC的网络IO模型的选择，至关重要。不同的网络IO模型，在高并发的状态下，处理性能上会有很大的差别。如Thrift提供支持以下IO模型的server实现: 单线程阻塞式IO服务模型 - TSimpleServer 多线程阻塞式IO服务模型 - TThreadPoolServer 非阻塞式IO服务模型 - TNonblockingServer 半同步半异步的服务模型 - THsHaServer 多线程半同步半异步的服务模型 - TThreadedSelectorServer Serialization &amp; Deserialization另外一个衡量RPC框架性能的标准，就是传输协议。通讯协议约定了RPC请求中client和server的通讯方式，序列化和反序列化属于通讯协议的一部分，是设计RPC框架时一个重要的考虑因素。在选择序列化/反序列化方式时通常需要考虑以下几个方面: 通用性 技术层面: 序列化协议是否支持跨平台、跨语言。 流行程度: 这通常意味着学习成本的高低和是否有足够的社区支持 强健性 协议的强健性依赖于大量而全面的测试，对于致力于提供高质量服务的系统，采用处于测试阶段的序列化协议会带来很高的风险。 可读性 序列化和反序列化的数据正确性和业务正确性的调试往往需要很长的时间，良好的调试机制会大大提高开发效率。这方面文本流比二进制流有明显的优点。 性能 主要在于空间开销(传输的数据量)和时间开销(序列化和反序列化时的CPU消耗) 可扩展性 好的序列化协议应该对于业务的扩展支持友好 主要的序列化/反序列化技术选型有以下几种: HTTPXMLXML是一种常用的序列化和反序列化协议，具有跨机器，跨语言等优点。webservice就完全基于XML通讯。可读性强，但是性能较差。异构系统，open api类型的应用中常用。 JSON将对象转换成JSON结构化字符串。在http协议下，这是常用的方案，具备Javascript的先天性支持。JSON可读性强，利于调试和排错，但是性能稍差。 TCPthriftThrift并不仅仅是序列化协议，而是一个RPC框架。Thrift在空间开销和解析性能上有了比较大的提升。Thrift框架本身并没有透出序列化和反序列化接口，这导致其很难和其他传输层协议共同使用 AvroAvro在大数据存储（RPC数据交换，本地存储）时比较常用 protobufProtobuf是一个纯粹的展示层协议，可以和各种传输层协议一起使用。它的主要问题在于其所支持的语言相对较少，另外由于没有绑定的标准底层传输层协议，在公司间进行传输层协议的调试工作相对麻烦。 各语言内置序列化/反序列化机制使用python pickle, java序列化库等 更多关于序列化和反序列化技术的对比，请参考: 序列化和反序列化 技术选型笔者遇到的RPC框架的技术组合有以下几种: Java: protobuf + netty Java: json + netty Python: thrift + thriftpy + thrift_connector + gunicorn thrift的相关库可以参考: thriftpy, swift 服务治理服务治理涵盖的内容很多，以下是服务治理的一些关键技术点 Service Registry服务注册中心，是服务治理最重要的组件之一。本质上是为了解耦服务提供者和服务消费者。可以基于ZooKeeper或者Etcd实现一套服务注册机制。 LB有了服务注册中心后，就可以在client拿到服务全部的列表，则对应的负载均衡策略在RPC框架的client里面做就可以了。这避免了haproxy配置复杂和不能热加载的问题。 Config Center同样可以基于zookeeper实现服务不同环境(开发，测试，预发布，生产)的配置功能 CI/CD可以基于jenkins和docker实现持续集成。服务的发布(灰度发布)同时需要一个完善的CMDB系统的存在 LogELK是比较成熟的日志分析技术栈 Monitoring &amp; Alerting关于监控和报警，请关注笔者的另外一篇文章: 服务监控和报警 Trace能够得到每一个调用的调用链路对于服务的分析有很大的辅助作用。trace系统的实现可以参考鹰眼下的淘宝_EagleEye with Taobao 限流，降级和熔断这三者都是服务自我保护的利器，均可以依赖于服务注册及配置中心实现。]]></content>
      <categories>
        <category>arch</category>
      </categories>
      <tags>
        <tag>arch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务监控和报警]]></title>
    <url>%2F2017%2F01%2F24%2Fmonitoring_and_alerting%2F</url>
    <content type="text"><![CDATA[背景对于应用开发团队来说，每天面对大量复杂多变业务逻辑的开发。为了发现潜在的问题，为了发生突发问题进行排障时有据可循，更为了了解服务的运行状况和服务性能，一个完善的自动化的监控报警系统非常必要。 系统架构监控系统一般监控系统的系统架构包括以下方面 指标收集agent指标的数据源主要有以下几个: 代码埋点 日志 数据库 一般增加一个collect agent用于统一数据格式，收集实时指标，同时用于数据的广播，解耦系统以及快速持久化等，同时将所有的指标发送到这个agent 传输由于指标是非业务数据，属于样本性质，可以容忍丢失。所以数据源到agent的数据传输，一般使用UDP协议 分析计算需要进行分析计算的指标维度一般有以下几种: Gauges: 代表一个度量的即时值。当你的程序运行的时候，内存使用量和CPU占用率都可以通过Gauge值来度量。 Counters: 就是计数器，是一个可以用来增加或者减少值的数。例如，可以用它来计数队列中加入的Job的总数。 Meters: 用来计算事件的速率。例如 request per second。还可以提供1分钟，5分钟，15分钟不断更新的平均速率 Histograms: 可以为数据流提供统计数据。除了最大值，最小值，平均值外，它还可以测量中值(median)，百分比比如XX%这样的Quantile数据 Timers: 用来测量一段代码被调用的速率和用时 显示 &amp; 通知对应的数据在进行计算后，需要进行显示。同时若有异常情况，需要通知关注的人员。 报警系统报警系统的数据来源和监控系统相似，只是在分析计算后添加了报警规则配置和报警事件生成层 监控报警系统的系统架构可以参考: 统一监控报警平台的架构设计思路分享 技术方案 数据的采集可以使用Statsd,Collectd 数据的存储可以使用Graphite carbon守护进程，接收Statsd发送过来的原始统计数据 whisper用来存储统计数据的库 graphite webapp用来图形化展示统计数据的web项目 数据的存储也可以使用influxdb 使用Grafana对指标进行展示 报警使用kapacitor 可以对技术方案进行以下组合: TICK(telegraf + influxdb + chronograf + kapacitor) statsd + graphite + grafana + banshee(ele.me使用) 监控设置完善的监控和报警可参考如下设置 服务 &amp; 接口 关键接口调用量，失败量 关键接口耗时 关键接口异常 自定义的业务指标监控，如交易中的买家数，金额等 基础服务 DB: 具体SQL响应时间，调用量，失败量，慢SQL数等 REDIS: 对应操作响应时间，调用量，失败量，cache命中率等 RMQ: 消息ready/unack/total数，publish/get速度(参看rabbitmq management插件提供的指标)，消息堆积数量等 应用服务器 cpu load, cpu util memory util, memory swap network-in, network-out, network-speed disk io TCP connection 报警设置报警主要针对以下情况 指标趋势 如某段时间指标值快速上升或者快速下降, 同环比趋势异常等 指标阈值 如调用量超过一定值，cache miss率超过一定值等 指标特殊值 如指标为0，为空等]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>devops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RPC(远程过程调用)和MQ(消息队列)]]></title>
    <url>%2F2017%2F01%2F23%2Frpc_and_mq%2F</url>
    <content type="text"><![CDATA[背景系统间互相调用时，是选择RPC还是MQ是经常需要权衡的问题，本文对两者的特点及适用场合进行简单的分析。 系统结构RPC系统结构12345+----------+ +----------+| Consumer | &lt;=&gt; | Provider |+----------+ +----------+Consumer调用Provider提供的服务 MQ系统结构12345+----------+ +-------+ +----------+| Producer | &lt;=&gt; | Queue | &lt;=&gt; | Consumer |+----------+ +-------+ +----------+Producer发送消息给Queue；Consumer从Queue拿消息来处理 功能特点相同点 都利于大型系统的解耦 都是用于子系统的交互和通信，特别是异构子系统的交互 RPC的特点 同步调用，是本地调用的扩展，对于要等待返回结果的场景，RPC是非常直觉的使用方式(当然RPC也可以是异步调用) 如果接口文件有变化，则Provider和Consumer都需要变更和重新部署 MQ的特点 MQ的请求和处理是异步的 MQ能够把请求暂存在broker，可以起到请求削峰的作用，Consumer可以按照自己的节奏来处理请求 MQ引入了一个新的结点(broker)，链路越长，系统的可靠性保障越低 MQ侧重数据的传输，因此方式更加多样化，除了点对点外，还有订阅发布等功能 如何选择 如果希望同步得到请求的处理结果，则选用RPC；如果基于性能的考虑，比如服务端不能快速的响应客户端（或客户端也不要求实时响应），不希望请求端受限于处理端的处理速度时，则选用MQ RPC是本地调用的扩展，使用简单；MQ的异步编程模式比较复杂 可靠性上: RPC可以通过同步调用的结果来决定是否进行补偿等操作，MQ一般不认为100%可靠。 对于有强一致性要求的场景，一般选择RPC 对于为了增加主流程性能，让其他次要流程异步操作时，可以选择MQ，如短信发送，日志记录，邮件服务，通知服务等。 如果调用侧重于点对点的功能调用，则选用RPC；如果侧重于数据的传输和广播，则选用MQ 参考 The case: RPC vs. Messaging]]></content>
      <categories>
        <category>arch</category>
      </categories>
      <tags>
        <tag>arch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库sharding]]></title>
    <url>%2F2017%2F01%2F21%2Fabout_sharding%2F</url>
    <content type="text"><![CDATA[概念数据库sharding，是指通过某种条件，把同一个数据库中的数据分散到多个数据库或多台机器上，以减小单台机器压力。 关于sharding更多的知识请参考: 数据库分库分表(sharding)系列 分类和维度分类垂直sharding以表为单位，把不同的表分散到不同的数据库或主机上。按领域模型，将业务紧密，表间关联密切的表划分在一起。特点是规则简单，实施方便，适合业务之间耦合度低的系统。 水平sharding以行为单位，将同一个表中的数据按照某种条件(譬如按ID散列)拆分到不同的数据库或主机上。特点是相对复杂，适合单表巨大的系统。 维度此处以电商为例 垂直维度: 按业务领域可以划分为booking，订单，商户，支付，物流等几个领域，可按此进行垂直拆分 水平维度: 电商中的两个最重要相关业务方为买家和卖家，最重要的业务为订单，所以可以依据买家和卖家信息生成订单，同时基于买家/卖家维度对相关表进行水平拆分 sharding实现层面从一个系统的程序架构层面来看，sharding逻辑可以在DAO层、JDBC API层、介于DAO与JDBC之间的Spring数据访问封装层(各种spring的template)以及介于应用服务器与数据库之间的sharding代理服务器四个层面上实现。 迁移随着业务的发展，一般都会有一个从非sharding向sharding迁移的过程，为了保证迁移过程中数据的准确性和迁移失败的可回退，迁移过程一般分为三个阶段: 双写读非sharding(此时需要校验非sharding和sharding库的数据一致性) 双写读sharding(此时还写非sharding是为了保证出问题时可以随时回退) 写sharding读sharding(切换完成) 系统由A状态过渡到B状态（系统的迁移）是另一个比较大也比较考验水平的话题 需要注意的地方全局主键一旦数据库被切分到多个物理结点上，我们将不能再依赖数据库自身的主键生成机制。此时可能需要一个全局主键生成机制，可以参考分布式系统中的全局唯一ID 引入分布式事务的问题一旦数据被切分到多个server中，势必会引入跨库事务的问题。此时可以考虑将一个跨多个数据库的分布式事务分拆成多个仅处于单个数据库上面的小事务，并通过应用程序来总控各个小事务。或者考虑一下分布式事务的解决方案 跨节点join的问题对应的解决方案为: 不使用复杂sql，这是比较推荐的作法，互联网行业一般只推荐使用简单sql 通过应用程序来进行处理，先在驱动表所在的DB中取出相应的驱动结果集，然后根据驱动结果集再到被驱动表所在的DB中取出相应的数据。 跨节点合并排序分页问题对应的解决方案为: 在应用程序中完成对应的合并排序分页。要记住一个基本原则: 尽量避免使用数据库做运算，因为数据库是不方便扩展的，因此只建议让数据库做基本的存储和事务保证功能。而应用服务器理论上是可以无限scale out的，所以资源消耗型的计算都建议由DB数据器移到应用服务器 使用搜索引擎解决。搜索引擎和CACHE实际都是DB功能的扩展，使用搜索引擎是很好地提高DB性能和弥补DB缺陷的手段 数据热点问题电商网站按买家ID分片的时候各分片间数据基本分布均匀，但是按卖家ID分片的时候由于可能存在热点卖家的问题，此时可能出现数据在某些分片集中，可以对热点分片考虑再分片。 迁移过程非sharding和sharding数据不一致由于各种原因，可能存在此问题。这是在迁移过程中需要解决的问题，只有两者数据一致时迁移第一阶段才算完成 多维度sharding数据不一致电商行业普通采用买家和卖家两维度的分片，此时由于两维度数据的提交不在同一个事务中，所以可能存在分布式事务的问题。为了保证两维度数据一致，可以考虑对另一维度的数据进行补偿（不考虑比较复杂的两阶段提交）]]></content>
      <categories>
        <category>arch</category>
      </categories>
      <tags>
        <tag>arch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式系统中的全局唯一ID]]></title>
    <url>%2F2017%2F01%2F20%2Fglobal_id%2F</url>
    <content type="text"><![CDATA[在分布式系统中，生成全局唯一ID的需求很常见。生成的方法主要有基于数据库生成，使用分布式集群协调器和划分命名空间并行生成等。 常用技术方案基于数据库生成这种类型的生成方案，都可以设置其初始值以及增量步长，一般包含以下几种: 使用mysql auto_increment特性 使用postgresql sequence特性 使用oracle的sequence特性 为了避免数据库的单点故障，还可以使用多台数据库服务器使用不同的步长来生成ID 各种基于数据库的全局唯一ID生成方案可以参考: http://www.cnblogs.com/heyuquan/p/global-guid-identity-maxId.html 基于分布式集群协调器生成在不使用数据库的情况下，通过一个后台服务对外提供高可用的、固定步长标识生成，则需要分布式的集群协调器进行。 一般的，主流协调器有两类： 以强一致性为目标的：ZooKeeper为代表 以最终一致性为目标的：Consul为代表 ZooKeeper的强一致性，是由Paxos协议保证的；Consul的最终一致性，是由Gossip协议保证的。 在步长累计型生成算法中，最核心的就是保持一个累计值在整个集群中的「强一致性」。但是，这也会为唯一性标识的生成带来新的形成瓶颈。 划分命名空间并行生成似乎对于分布式的ID生成，以Twitter Snowflake为代表的， Flake 系列算法，经常可以被搜索引擎找到，但似乎MongoDB的ObjectId算法，更早地采用了这种思路。 snowflake是Twitter开源的分布式ID生成算法，结果是一个long型的ID。其核心思想是：使用41bit作为毫秒数，10bit作为机器的ID（5个bit是数据中心，5个bit的机器ID），12bit作为毫秒内的流水号（意味着每个节点在每毫秒可以产生 4096 个 ID），最后还有一个符号位，永远是0。snowflake算法可以根据自身项目的需要进行一定的修改。比如估算未来的数据中心个数，每个数据中心的机器数以及统一毫秒可以能的并发数来调整在算法中所需要的bit数。 我的Global Id用于标识电商网站订单号 特性 12-19位int类型。方便用户阅读使用，同时数据库长整数字型的数据索引与检索效率，远远高于文本型。(Java long型对应 2 ^ 64为20位10进制型，所以也在long范围内) 需要标识业务/技术属性 业务属性 订单类型，如实物商品/虚拟商品 外卖订单/团购订单 … 技术属性 IDC归属 测试订单 … 考虑到长度问题，不考虑包含时间因素 包含卖家/买家信息 设计1[自增部分] + [1位业务标识] + [1位技术标识] + [3位商家标识] + [3位用户标识] 自增部分用来保证订单号的唯一以及订单号的有序，使用DB自增生成 业务标识用来标识业务属性 技术标识用来标识技术属性 商户ID散列值 mod 512，可以用来做商户维度的sharding，根据笔者经验，大中型网站分片数512已经足够。同时不考虑2/10进制转换来标识sharding，也是为了阅读方便 用户ID散列值 mod 512，可以用来做用户维度的sharding 容量评估假设订单长度大于12位(后8位为标识位)，则自增的起始值为1,000。到20位时，自增值为1000,0000,0000。以1000,0000单一天计算，则订单号可以使用 1(100000000000 - 1000) / 10000000 / 365 = 27(年) 存储及使用自增的起始值存储在mysql中，使用的过程如下: 123456789101112131415161718192021queue = multiprocessing.Queue()def get_global_id(): order_id = queue.get() if order_id: // fetch from queue return order_id else: // fetch from db order_id_list = fetch_id_list_from_db() for order_id in order_id_list: queue.put(order_id) order_id = queue.get() return order_id def fetch_id_list_from_db(): db.select_for_update() // db获取悲观锁，注意此时表只有一行，所以需要通过ID获取行锁，忌使用表锁 order_ids = db.select(1000) // 一次取1000个order id db.sequence.update(1000) // db sequence 字段增加1000 db.commit() return order_ids]]></content>
      <categories>
        <category>arch</category>
      </categories>
      <tags>
        <tag>arch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于timeout]]></title>
    <url>%2F2017%2F01%2F16%2Fabout_timeout%2F</url>
    <content type="text"><![CDATA[使用Timeout，是一种常见的容错模式。常见的有设置网络连接超时时间，一次RPC的响应超时时间等。在分布式服务调用的场景中，它主要解决了当依赖服务出现建立网络连接或响应延迟，不用无限等待的问题，调用方可以根据事先设计的超时时间中断调用，及时释放关键资源，如Web容器的连接数，数据库连接数等，避免整个系统资源耗尽出现拒绝对外提供服务这种情况。 意义: 当网络出现短暂的抖动，或者下游服务调用超时时，合理的超时时间可以避免连接池快速被占满，可有效延长服务的可用时长 可以结合降级，熔断等SOA治理的手段使用 原理阻塞IO的timeout由于我们常用的socket都是阻塞的，那么超时是很好设置的，直接设置socket的超时就可以了。 1234// send timeoutsetsockopt(socket，SOL_S0CKET,SO_SNDTIMEO，(char *)&amp;nNetTimeout,sizeof(int));// receive timeoutsetsockopt(socket，SOL_S0CKET,SO_RCVTIMEO，(char *)&amp;nNetTimeout,sizeof(int)); Java的超时设置可以参考: Java: Set timeout for threads in a ThreadPool 对应代码如下: 1234567891011121314Future&lt;?&gt; future = null;for (List&lt;String&gt; l : partition) &#123; Runnable worker = new WorkerThread(l); future = executor.submit(worker);&#125;try &#123; System.out.println(&quot;Started..&quot;); System.out.println(future.get(3, TimeUnit.SECONDS)); System.out.println(&quot;Finished!&quot;);&#125; catch (TimeoutException e) &#123; System.out.println(&quot;Terminated!&quot;);&#125; 非阻塞IO的timeout但是，用过Linux下非阻塞I/O的都知道，非阻塞情况下，设置连接超时神马都是浮云的，因为人家是非阻塞的。典型的譬如Python的gevent，在用monkey.patch_all()之后，所有的socket都会被转化为非阻塞的，这时候的timeout设置就失效了。这种情况下gevent提供了Timeout类，当你的类似sleep（由于I/O、sleep等原因挂起）超时超过了Timeout的时间限制后，会自动终止block，跳出。使用方法如下: 1234567891011121314import geventimport gevent.monkeyimport timegevent.monkey.patch_all()def test(): with gevent.Timeout(5) as timeout: time.sleep(10) print &quot;time out&quot;if __name__ == &quot;__main__&quot;: g = gevent.spawn(test) g.join() 最佳实践为了让client尽快得到响应，也为了尽量减少服务响应延迟时的服务资源消耗，需要设置client timeout(客户端timeout), server timeout(服务端timeout)以及service timeout(基础服务如mysql等timeout)。同时需要根据实际情况设置一条请求链路上对应client,server和service的timeout。 一般需要考虑以下情况: 设置client timeout保证client尽快得到响应，同时方便重试 设置server timeout保证及时释放服务器资源，保证不被client拖垮 设置一些基础服务的timeout，可以有效保护对应资源，避免整个系统资源耗尽出现拒绝对外提供服务这种情况 timeout值的考虑 一条链路上游至下游如果只是一次Request/Response的话，那么对应的timeout值应该逐渐减少，如RPC请求的Client和Server端（保证请求的时间范围覆盖了响应的时间范围） 如果有多次交互的话，无需要考虑。如server请求DB，Server先发送commit到DB，若Server超时后再发rollback给DB。则DB的timeout无需要比Server短，只需要考虑DB自身的性能即可 mysql timeout实验目的: 实验client通过RPC请求SERVER，同时操作MYSQL时相应timeout的最佳设置 背景table结构如下: 12345678&lt;resultMap id=&quot;BaseResultMap&quot; type=&quot;me.ele.fin.job.dal.model.TestModel&quot;&gt; &lt;id column=&quot;id&quot; property=&quot;id&quot; jdbcType=&quot;BIGINT&quot;/&gt; &lt;result column=&quot;restaurant_id&quot; property=&quot;restaurantId&quot; jdbcType=&quot;BIGINT&quot;/&gt; &lt;result column=&quot;order_id&quot; property=&quot;orderId&quot; jdbcType=&quot;BIGINT&quot;/&gt; &lt;result column=&quot;status&quot; property=&quot;status&quot; jdbcType=&quot;TINYINT&quot;/&gt; &lt;result column=&quot;created_at&quot; property=&quot;createdAt&quot; jdbcType=&quot;TIMESTAMP&quot;/&gt; &lt;result column=&quot;updated_at&quot; property=&quot;updatedAt&quot; jdbcType=&quot;TIMESTAMP&quot;/&gt; &lt;/resultMap&gt; 对应RPC请求接口逻辑如下: 12345678910111213141516@Transactional(timeout = 10)public int updateTestStatus(Long id) throws JobServiceException &#123; Long startTime = System.currentTimeMillis(); int updateRes = 0; try &#123; updateRes = testMapper.updateById(id); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; Long endTime = System.currentTimeMillis(); String duration = DurationFormatUtils.formatPeriod(startTime, endTime, &quot;S&quot;); logger.info(&quot;update result: &quot; + updateRes); logger.info(&quot;Duration milliseconds: &quot; + duration); return 1;&#125; mysql对应timeout设置如下: 123456789101112131415161718mysql&gt; show variables like &quot;%timeout%&quot;;+-----------------------------+----------+| Variable_name | Value |+-----------------------------+----------+| connect_timeout | 10 || delayed_insert_timeout | 300 || innodb_flush_log_at_timeout | 1 || innodb_lock_wait_timeout | 50 || innodb_rollback_on_timeout | OFF || interactive_timeout | 28800 || lock_wait_timeout | 31536000 || net_read_timeout | 30 || net_write_timeout | 60 || rpl_stop_slave_timeout | 31536000 || slave_net_timeout | 3600 || wait_timeout | 28800 |+-----------------------------+----------+12 rows in set (0.00 sec) 步骤1. 设置autocommit为OFF1set autocommit = 0; 2. 锁定某一条记录12begin;select * from test where id = 1 for update; 锁定id为1的记录 3. 调用接口，update同一条记录运行以下JUnit测试 123456789101112131415161718public class JobServiceTest extends TestBase &#123; @Autowired private IJobService ijs; /** * 测试本地服务 */ @Test public void testServiceFromLocalContext() throws JobServiceException &#123; try &#123; int returnVal = ijs.updateTestStatus(1L); Assert.assertTrue(returnVal == 1); &#125; catch (JobServiceException ex) &#123; ex.printStackTrace(); &#125; &#125;&#125; 结果及结论使用postman模拟client调用对应接口，设select for update为事务1，接口调用为事务2。 0 - 10s 内，提交事务1(运行commit手动提交), 则事务2可以获取innodb锁往下执行，最后事务2也正确提交 10 - 50s 内，提交事务1，则事务2roll back，同时立刻返回结果给client，表示@Transactional(timeout = ?)可以设置在多长时间后，应用逻辑中mysql事务失败，事务2会rollback，同时返回结果给client（快速失败） &gt;50s 后，由于innodb_lock_wait_timeout的存在，事务1和事务2都会roll back，且打印以下log 122017-01-16 14:04:23.810 INFO xxx.job.service.JobService[main]: [unknown 1.1 unknown^^2337080905338436383|1484546598112] ## update result: 02017-01-16 14:04:23.810 INFO xxx.job.service.JobService[main]: [unknown 1.1 unknown^^2337080905338436383|1484546598112] ## Duration milliseconds: 51288]]></content>
      <categories>
        <category>arch</category>
      </categories>
      <tags>
        <tag>arch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于幂等]]></title>
    <url>%2F2017%2F01%2F10%2Fabout_idempotency%2F</url>
    <content type="text"><![CDATA[幂等方案可以保证幂等的操作1. 查询操作查询一次和查询多次，在数据不变的情况下，查询结果是一样的。在隔离级别为可重复读(mysql默认隔离级别)时，select是天然的幂等操作 2. 删除操作删除操作也是幂等的，删除一次和多次删除结果相同，都是把数据删除。(注意可能返回结果不一样，删除的数据不存在，返回0；删除的数据多条，返回结果多个) 3. 唯一索引唯一索引或唯一组合索引来防止提交重复数据，不过对DB性能有影响 4. 悲观锁获取数据的时候加锁获取 1select * from table_xxx where id=&apos;xxx&apos; for update; 5. 乐观锁乐观锁只是在更新数据那一刻锁表，其他时间不锁表，所以相对于悲观锁，效率更高。 乐观锁的实现方式多种多样，可以通过version或者其他状态条件： 通过版本号实现 1update table_xxx set name=#name#,version=version+1 where id=#id# and version=#version# 通过条件限制 1update table_xxx set total=total-#hongbao# where id=#id# and total-#hongbao# &gt; 0 6. 分布式锁如果是分布式系统，构建全局唯一索引比较困难，例如唯一性的字段没法确定，这时候可以引入分布式锁，通过第三方的系统(redis或zookeeper)，在业务系统插入数据或者更新数据，获取分布式锁，然后做操作，之后释放锁。 或者在执行接口的逻辑前，先在mysql表中插入接口的特征值(此字段设置unique)，用mysql保证对应的业务逻辑只执行一次。 分布式锁的java实现及使用: https://github.com/redisson/redisson https://my.oschina.net/wangnian/blog/668830 7. 状态机幂等状态在不同的情况下会发生变更，一般情况下存在有限状态机(fsm)，这时候，如果状态机已经处于下一个状态，这时候来了一个上一个状态的变更，理论上是不能够变更的，这样的话，保证了有限状态机的幂等。 伪代码如下: 123// 如果状态已经发生变更，直接returnif fsm.status = expected_status: return 不推荐的方案1. select + insert并发不高的后台系统，或者一些任务JOB，为了支持幂等，支持重复执行，简单的处理方法是，先查询下一些关键数据，判断是否已经执行过，再进行业务处理。这种方法在高并发时会出现问题 几条基本原则 DB不能DOWN，DB不能DOWN，DB不能DOWN 这是最重要的前提。不管是使用连接池，使用缓存，使用搜索，还是DAL的限流。所有这些措施的最重要作用首先都是为了保证数据库的正常运行，防止数据库DOWN，然后才是为了提高性能 业务要保证正确 业务的正确保证不需要多言。所以为了避免插入重复数据时，DB需要设置唯一键（尽管这会降低DB性能） 性能优化是最后考虑的事 只有DB服务器正常运行，业务正确的前提下，再开始考虑优化性能 推荐方案所以在防止插入重复数据时，推荐的方案是: 使用redis作为接口锁，防止重复请求到达数据库，对数据库性能造成冲击（初步的幂等保证及数据库保护） 使用唯一键保证不插入重复数据（最后的兜底及最终保证）]]></content>
      <categories>
        <category>arch</category>
      </categories>
      <tags>
        <tag>arch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python Is Not Java]]></title>
    <url>%2F2017%2F01%2F05%2Fpython-is-not-java%2F</url>
    <content type="text"><![CDATA[语言上的差异讲述的地方很多，可以参考: Java 和 Python 有哪些区别。 这里主要是讲述一些语言风格/编程思维的对比 Python/Java风格对比1. 平铺的结构比嵌套的要好 Java中的静态方法不能翻译成Python的类方法。Java静态方法惯用的翻译通常翻译成一个模块级的函数，而不是一个类方法或静态方法。(并且静态常量应该翻译成模块级常量)。这不是性能上的问题，但是一个Python程序员如果想调用Foo.someMethod，他要是被迫采用像Java中Foo.Foo.someMethod的方式去做的话，那么他就会被逼疯的。有一点一定要注意:调用一个类方法需要一个额外的存储空间,而调用静态方法或函数就不需要这样. Python中,要记住一点,平铺的结构比嵌套的要好,尽管相对于从性能方面来说,可能它更多涉及的是”可读性”和”简单要比复杂好”。 2. 拒绝XML。比起Java代码，XML是灵活而且有弹性的。但比起Python的代码来，XML就是一个船锚，一个累赘。 如果你不是因为信息交互的原因去实现一个已经存在的XML标准或是建立某种输入、输出格式或者建立某种XML编辑器或处理工具，那么就不要在python中考虑XML 3. Getter和setter是恶魔 Python对象不是Java Bean。不要写什么getter和setter。它们是CPU时间的浪费，更要紧的是，它们还是程序员宝贵时间的浪费。 在Java中，你必须使用getter和setter,因为公共字段不允许你以后改变想法再去使用getter和setter。所以,在Java中你最好事先避开这些”家务杂事”.在Python中，这样做很傻，因为你可以以一个普通特性开始并可以在任何时间改变你的想法，而不用影响到这个类的任何客户。所以不要写getter和setter方法。 4. 代码重复在Java中通常来说就是一场不可避免的灾祸，但Python可以避免 在Python中，你写了一个包含了函数的函数。这里内部的函数就是你要一遍遍写的函数的模版，但是在里面加入了针对不同情况的函数要使用变量。外部的函数需要刚刚提高的那种变量作为参数，并且将内部的函数作为结果返回。然后，每次你要写另一种略微不同的函数的时候，你只要调用这个外部的函数，并且把返回值赋给你要让“重复”函数出现的名字。现在，如果你需要改变这个工作方式，你只需要改变一个地方：这个模版。 Java编程思维的吐槽另外转一个关于Java的吐槽，相对于Python和Java的比较也符合: 风格的问题。这个问题我认为是最严重的。基础软件开发崇尚的是自由、直接、透明、简单、高效，要像匕首一样锋利，像战士一样勇猛，像农夫一样朴实，反对繁琐华丽的设计，反对架床迭屋的层层抽象，反对复杂的结构和不必要的灵活性。而Java社群多年来形成的设计风格与此格格不入，甚至可以说是对立的。Java在意识形态上是要面向企业应用软件的开发，所以特别强调架构，强调设计模式，强调标准，强调规规矩矩，强调高姿态，强调一种华贵的宫廷气质。在C中，你吃饭就是吃饭，捧起碗来喝酒，放下筷子骂娘，甩开膀子抓肉，撸起袖子抹油。而在Java中，你经常为了要干某件事，先new一个对象，然后以这个对象为参数new另一个对象，如此这般重复n遍，得到真正需要的对象，最后就是为了调用那个对象的一个方法，就好比吃饭时焚香洗面，漱口净手，战战兢兢，毕恭毕敬。在C中，遇到问题要像亡命徒，像流氓版程咬金，管你三七二十一，冲上去就是三板斧，还怕劈不死你丫的。在Java里，遇到问题要像宋襄公，要张榜檄文，要名正言顺，要礼仪之邦，要把架子拉开了，把谱儿摆足了。Java的口号是，不管劈不劈的死，先把你小子感动了再说。 这套繁琐的东西，对于基础软件开发来说，既不必要，也很难习惯。需要说明的是，这不是Java语言的问题，其实Java本身不必如此复杂、如此巴洛克。从语言本身来看，Java也可以是轻快直接的，也可是酣畅淋漓的。只不过十多年来几乎没有人这样用过，所以大家已经不知道：如果不来个一步三叩首，那么该怎么用Java写程序？]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的vim]]></title>
    <url>%2F2016%2F12%2F15%2Fmy_vim%2F</url>
    <content type="text"><![CDATA[关于vim常言道: 工欲善其事，必先利其器。作为一个程序员，一个常用的工具就是编辑器。相比IDE，vim具有以下几种特性: 跨平台及统一环境 无论是在windows还是在*nix，vim是一个很完美的跨平台文本编辑器。 定制化及可扩展 vim提供一个vimrc的配置文件来配置vim，并且自己可以定制一些插件来实现各种功能 高效命令行 使用vim编辑文本，只需在键盘上操作就可以，根本无需用到鼠标。 笔者最终配置的vim如下图所示: 对应的repo为: https://github.com/joshua-hw/my_vim 配置如果你需要配置vim，只需在Home目录创建一个~/.vimrc文件即可以配置vim了。以下是笔者的.vimrc文件内容。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394&quot;自己定义vimrc常见设置和一些键位的设置&quot;---------------- 加载插件管理文件 --------------------if filereadable(expand(&quot;~/.vimrc.bundles&quot;)) source ~/.vimrc.bundlesendif&quot; 在插入模式下MAC下的delete不能删除问题set backspace=2set colorcolumn=80&quot;--------------- leader设定 -------------let mapleader = &apos;,&apos;let g:mapleader = &apos;,&apos;&quot;------------------------------- 基本设置 -----------------------------------&quot;开启语法高亮&quot;syntax enable 该命令只在当前文件有效syntax on &quot; 所有缓冲区文件都有效&quot;-------------- 文件检测 ----------------------filetype onfiletype indent onfiletype plugin onfiletype plugin indent oncolorscheme blackbeauty &quot; 配色主题set autoread &quot; 文件修改之后自动载入。set shortmess=atI &quot; 启动的时候不显示那个援助索马里儿童的提示set laststatus=2&quot;set confirm &quot; 取消光标闪烁set noswapfile &quot; 关闭交换文件set wildignore=*.swp,*.bak,*.pyc,*.class,.svnset cursorcolumn &quot; 突出显示当前列set cursorline &quot; 突出显示当前行set title set novisualbellset noerrorbellsset magicset ruler &quot; 显示当前行号和列号set number &quot; 显示行号set nowrap &quot; 取消换行set showcmd &quot; 在状态栏显示正在输入的命令set showmode &quot; 显示vim模式set showmatch &quot; 括号匹配，高亮set matchtime=1 set hlsearch &quot; 高亮搜索的文本set incsearch &quot; 即时搜索set ignorecase &quot; 搜索忽略大小写set smartcase &quot; 有一个或以上大写字母时仍大小敏感set foldenable &quot; 代码折叠set foldmethod=indentset foldlevel=99 &quot; autosave&quot;let g:auto_save = 1 &quot; enable AutoSave on Vim startup&quot;let g:auto_save_no_updatetime = 1 &quot; do not change the &apos;updatetime&apos; option&quot;let g:auto_save_in_insert_mode = 0 &quot; do not save while in insert mode&quot;let g:auto_save_silent = 1 &quot; do not display the auto-save notification&quot;let g:auto_save_events = [&quot;InsertLeave&quot;, &quot;TextChanged&quot;]&quot;let g:auto_save_keep_marks = 0&quot; 代码折叠自定义快捷键let g:FoldMethod = 0map &lt;leader&gt;zz :call ToggleFold()&lt;cr&gt;fun! ToggleFold() if g:FoldMethod == 0 exe &quot;normal! zM&quot; let g:FoldMethod = 1 else exe &quot;normal! zR&quot; let g:FoldMethod = 0 endifendfunset smartindent &quot; 智能缩进set autoindent &quot; 自动缩进&quot;------------------------------- tab 相关设置 ---------------------set tabstop=4 &quot; 设置tab的宽度set shiftwidth=4 &quot; 每一次缩进对应的空格数set softtabstop=4 &quot; 按退格键是可以一次删除4个空格set smarttab set expandtab &quot; 将tab自动转化为空格set shiftround &quot; 缩进时，取整&quot;------------------------------- 文件编码 -------------------------set encoding=utf-8set fileencodings=utf-8,ucs-bom,shift-jis,gb18030,gbkgb2312,cp936 &quot; 自动判断编码set helplang=cnset ffs=unix,mac,dosset formatoptions+=B &quot; 合并两行中文时，不在中间加空格set termencoding=utf-8 &quot; 终端编码&quot;------------------------------- 其他设置 -------------------------set completeopt=longest,menu &quot; 让vim的补全菜单和ide一致set wildmenuset wildignore=*.0,*~,*.pyc,*.classautocmd! bufwritepost .vimrc source % &quot; vimrc 文件修改后自动加载&quot;------------------------------- 自定义快捷键设置 -----------------&quot; 关闭方向键，使用hjklmap &lt;Left&gt; &lt;Nop&gt; map &lt;Right&gt; &lt;Nop&gt;map &lt;Up&gt; &lt;Nop&gt;map &lt;Down&gt; &lt;Nop&gt; &quot; 行首 和 行尾 mapnoremap H ^noremap L $&quot; 切换到命令模式map noremap ; :&quot; 插入模式下 kj 映射到 Escinoremap kj &lt;Esc&gt; nnoremap &lt;leader&gt;q :q!&lt;CR&gt;nnoremap &lt;leader&gt;w :wq&lt;CR&gt;&quot; 分屏切换noremap w&lt;up&gt; &lt;c-w&gt;&lt;up&gt;noremap wk &lt;c-w&gt;&lt;up&gt;noremap w&lt;left&gt; &lt;c-w&gt;&lt;left&gt;noremap wh &lt;c-w&gt;&lt;left&gt;noremap w&lt;right&gt; &lt;c-w&gt;&lt;right&gt;noremap wl &lt;c-w&gt;&lt;right&gt;noremap w&lt;down&gt; &lt;c-w&gt;&lt;down&gt;noremap wj &lt;c-w&gt;&lt;down&gt;&quot; python 文件的一般设置autocmd FileType python set tabstop=4 shiftwidth=4 expandtab ai&quot; php自动完成autocmd FileType php set omnifunc=phpcomplete#CompletePHP&quot; 当文件类型为php时，将系统自动补全的快捷键更改为 ,aautocmd FileType php inoremap &lt;leader&gt;a &lt;C-x&gt;&lt;C-o&gt;&quot; 只有在是PHP文件时，才启用PHP补全au FileType php call AddPHPFuncList()function! AddPHPFuncList() set dictionary-=~/.vim/funclist.txt dictionary+=~/.vim/funclist.txt set complete-=k complete+=kendfunction&quot; phpqalet g:phpqa_php_cmd=&apos;php&apos;let g:phpqa_codesniffer_args = &quot;--standard=PSR2&quot; &quot; Set the codesniffer argslet g:phpqa_codesniffer_cmd=&apos;phpcs&apos; &quot; PHP Code Sniffer binary (default = \&quot;phpcs\&quot;)let g:phpqa_messdetector_cmd=&apos;phpmd&apos; &quot; PHP Mess Detector binary (default = \&quot;phpmd\&quot;)let g:phpqa_messdetector_autorun = 0 &quot; Don&apos;t run messdetector on save (default = 1)let g:phpqa_codesniffer_autorun = 0 &quot; Don&apos;t run codesniffer on save (default = 1)let g:phpqa_codecoverage_autorun = 1 &quot; Show code coverage on load (default = 0)&quot; Clover code coverage XML file&quot; let g:phpqa_codecoverage_file = \&quot;/path/to/clover.xml\&quot;&quot; &quot; Show markers for lines that ARE covered by tests (default = 1)let g:phpqa_codecoverage_showcovered = 0 &quot; Stop the location list opening automaticallylet g:phpqa_open_loc = 0&quot; 定义函数AutoSetFileHead，自动插入文件头autocmd BufNewFile *.sh,*.py exec &quot;:call AutoSetFileHead()&quot;function! AutoSetFileHead()&quot;如果文件类型为.sh文件if &amp;filetype == &apos;sh&apos; call setline(1, &quot;\#!/bin/bash&quot;)endif&quot;如果文件类型为pythonif &amp;filetype == &apos;python&apos; call setline(1, &quot;\#!/usr/bin/env python&quot;) call append(1, &quot;\# -*- coding: utf-8 -*- &quot;)endif normal G normal o normal oendfunc&quot;set some keyword to highlightif has(&quot;autocmd&quot;) &quot;Highlight TODO, FIXME, NOTE, etc. if v:version &gt; 701 autocmd Syntax * call matchadd(&apos;Todo&apos;, &apos;\W\zs\(TODO\|FIXME\|CHANGED\|DONE\|XXX\|BUG\|HACK\)&apos;) autocmd Syntax * call matchadd(&apos;Debug&apos;, &apos;\W\zs\(NOTE\|INFO\|IDEA\|NOTICE\)&apos;) endifendif&quot; ----------------------- 插件设置 ------------------------------&quot; *********************** NERDTree 插件设置 *********************&quot; vim启动时触发&quot; autocmd vimenter * NERDTreemap &lt;leader&gt;n :NERDTreeToggle&lt;CR&gt;autocmd bufenter * if (winnr(&quot;$&quot;) == 1 &amp;&amp; exists(&quot;b:NERDTreeType&quot;) &amp;&amp; b:NERDTreeType == &quot;primary&quot;) | q | endiflet NERDTreeShowLineNumbers=1let NERDTreeIgnore=[&apos;\.pyc$&apos;, &apos;\~$&apos;]&quot; 分屏打开文件let g:NERDTreeMapOpenVSplit = &apos;v&apos; let g:NERDTreeMapOpenSplit = &apos;s&apos; &quot; *********************** tagbar 插件设置 ***********************map &lt;leader&gt;g :TagbarToggle&lt;CR&gt;let g:tagbar_auto_focus=1&quot; *********************** taglist 插件设置 **********************let Tlist_Ctags_Cmd=&quot;/usr/local/bin/ctags&quot;let Tlist_Show_One_File=1let Tlist_Exit_OnlyWindow=1let Tlist_Auto_Open=0let Tlist_Auto_Highlight_Tag=1let Tlist_Use_Right_Window=1let Tlist_WinWidth=35&quot; *********************** 快速跳转 ******************************let g:EasyMotion_smartcase=1map &lt;leader&gt;&lt;leader&gt;h &lt;Plug&gt;(easymotion-linebackward)map &lt;leader&gt;&lt;leader&gt;j &lt;Plug&gt;(easymotion-j)map &lt;leader&gt;&lt;leader&gt;k &lt;Plug&gt;(easymotion-k)map &lt;leader&gt;&lt;leader&gt;l &lt;Plug&gt;(easymotion-lineforward)map &lt;leader&gt;&lt;leader&gt;. &lt;Plug&gt;(easymotion-repeat)&quot; *********************** 语法检查 ******************************let g:syntastic_error_symbol=&apos;&gt;&gt;&apos;let g:syntastic_warning_symbol=&apos;&gt;&apos;let g:syntastic_check_on_open=1let g:syntastic_check_on_wq=0let g:syntastic_enable_highlighting=1let g:syntastic_python_checkers=[&apos;pyflakes&apos;, &apos;pep8&apos;]let g:syntastic_python_pep8_args=&apos;--ignore=E501,E225&apos;let g:syntastic_always_populate_loc_list=0let g:syntastic_auto_loc_list=0let g:syntastic_loc_list_height=3function! ToggleErrors() let old_last_winnr = winnr(&apos;$&apos;) lclose if old_last_winnr == winnr(&apos;$&apos;) &quot;Nothing was closed, open syntastic error location panel Errors endifendfunctionnnoremap &lt;leader&gt;s :call ToggleErrors()&lt;cr&gt;&quot; *********************** autopep8语法检查 ******************************let g:autopep8_max_line_length=79&quot; *********************** 自动补全引号等插件设置 ****************au FileType python let b:delimitMate_nesting_quotes = [&apos;&quot;&apos;]&quot; ********************** 全局搜索 ***********************let g:ag_prg = &quot;ag --nogroup --nocolor --column&quot;&quot; python 相关语法检查let g:pyflakes_use_quickfix = 0let python_highlight_all = 1&quot; *********************** markdown 插件设置 *********************let g:vim_markdown_folding_disable = 1&quot; 多光标选中编辑设置&quot; let g:multi_cursor_use_default_mapping = 0&quot; let g:multi_cursor_next_key=&apos;&lt;C-m&gt;&apos;&quot; let g:multi_cursor_prev_key=&apos;&lt;C-p&gt;&apos;&quot; let g:multi_cursor_skip_key=&apos;&lt;C-x&gt;&apos;&quot; let g:multi_cursor_quit_key=&apos;&lt;Esc&gt;&apos;&quot; *********************** 快速注释 ******************************let g:NERDSpaceDelims = 1&quot; *********************** 文件搜索插件 **************************let g:ctrlp_map = &apos;&lt;leader&gt;p&apos;let g:ctrlp_cmd = &apos;CtrlP&apos;map &lt;leader&gt;f : CtrlPMRU&lt;CR&gt;let g:ctrlp_custom_ignore = &#123; \ &apos;dir&apos;: &apos;\v[\/]\.(git|hg|svn|rvm)$&apos;, \ &apos;file&apos;: &apos;\v\.(exe|so|dll|zip|tar|tar.gz|pyc)$&apos;, \&#125;let g:ctrlp_working_path_mode=0let g:ctrlp_match_window_bottom=1let g:ctrlp_max_height=15let g:ctrlp_match_window_reversed=0let g:ctrlp_mruf_max=500let g:ctrlp_follow_symlinks=1&quot; ctrlp相关插件 函数搜索nnoremap &lt;Leader&gt;fu: CtrlPFunky&lt;Cr&gt;nnoremap &lt;Leader&gt;fU:execute &apos;CtrlpFunky &apos; . expand(&apos;&lt;cword&gt;&apos;)&lt;Cr&gt;let g:ctrlp_funky_syntax_highlight = 1let g:ctrlp_extensions = [&apos;funky&apos;]&quot; *********************** pyflakes_vim 插件设置 *****************let g:pyflakes_user_quickfix=0&quot; *********************** python-syntax *************************let python_highlight_all=1&quot; *********************** vim-markdown **************************let g:vim_mardown_folding_disabled=1&quot; *********************** 自动补全插件 **************************let g:ycm_key_list_select_completion=[&apos;&lt;Down&gt;&apos;]let g:ycm_key_lsit_previous_completion=[&apos;&lt;Up&gt;&apos;]let g:ycm_complete_in_comments = 1 &quot;在注释输入中也能补全let g:ycm_complete_in_strings = 1 &quot;在字符串输入中也能补全let g:ycm_use_ultisnips_completer = 1 &quot;提示UltiSnipslet g:ycm_collect_identifiers_from_comments_and_strings = 1 &quot;注释和字符串中的文字也会被收入补全let g:ycm_collect_identifiers_from_tags_files = 1&quot; ********************** 对齐线设置 ****************************let g:indent_guides_enable_on_vim_startup = 0let g:indent_guides_auto_colors = 0let g:indent_guides_guide_size = 1 set ts=4 sw=4 etlet g:indent_guides_start_level = 2autocmd VimEnter,Colorscheme * :hi IndentGuidesOdd guibg=red ctermbg=3autocmd VimEnter,Colorscheme * :hi IndentGuidesEven guibg=green ctermbg=4hi IndentGuidesOdd guibg=red ctermbg=3hi IndentGuidesEven guibg=green ctermbg=4&quot; 跳转到定义处, 分屏打开let g:ycm_goto_buffer_command = &apos;vertical-split&apos;nnoremap &lt;leader&gt;jd :YcmCompleter GoToDefinitionElseDeclaration&lt;CR&gt;nnoremap &lt;leader&gt;gd :YcmCompleter GoToDeclaration&lt;CR&gt;&quot; 引入，可以补全系统，以及python的第三方包 针对新老版本YCM做了兼容&quot; old versionif !empty(glob(&quot;~/.vim/bundle/YouCompleteMe/cpp/ycm/.ycm_extra_conf.py&quot;)) let g:ycm_global_ycm_extra_conf =&quot;~/.vim/bundle/YouCompleteMe/cpp/ycm/.ycm_extra_conf.py&quot;endif&quot; new versionif !empty(glob(&quot;~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/ycm/.ycm_extra_conf.py&quot;)) let g:ycm_global_ycm_extra_conf = &quot;~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/ycm/.ycm_extra_conf.py&quot;endif&quot; 直接触发自动补全 insert模式下&quot; let g:ycm_key_invoke_completion = &apos;&lt;C-Space&gt;&apos;let g:ycm_key_list_select_completion=[&apos;&lt;tab&gt;&apos;, &apos;&lt;Down&gt;&apos;]&quot; 黑名单,不启用let g:ycm_filetype_blacklist = &#123; \ &apos;tagbar&apos; : 1, \ &apos;gitcommit&apos; : 1, \&#125;&quot; last_edit_marker.vim设置nmap &lt;C-y&gt; g&apos;Zaugroup LastEditMarker autocmd! autocmd InsertLeave * normal mZaugroup END&quot; vim，主机复制共享vmap &lt;C-c&gt; &quot;+yvmap &lt;C-x&gt; &quot;+c vmap &lt;C-v&gt; c&lt;ESC&gt;&quot;+p imap &lt;C-v&gt; &lt;C-r&gt;&lt;C-o&gt;+ nmap &lt;C-v&gt; &quot;+p&quot; powerline设置set guifont=PowerlineSymbols\ for\ Powerlineset nocompatibleset laststatus=2set t_Co=256let g:Powerline_symbols = &apos;fancy&apos;let Powerline_symbols=&apos;compatible&apos; &quot; gitgutter设置let g:gitgutter_map_keys = 0let g:gitgutter_enabled = 0let g:gitgutter_highlight_lines = 1nnoremap &lt;leader&gt;gs :GitGutterToggle&lt;CR&gt; 插件使用vumdle管理vim的插件，使用过程如下: 在Home目录创建~/.vim目录和.vimrc文件，可使用上面的.vimrc文件 安装vundle 1git clone https://github.com/gmarik/vundle.git ~/.vim/bundle/vundle 添加一个~/.vimrc.bundles文件来保存所有插件的配置，在~/.vimrc文件加入以下代码片段 123if filereadable(expand(&quot;~/.vimrc.bundles&quot;))source ~/.vimrc.bundlesendif 以下是笔者的.vimrc.bundles文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273set nocompatiblefiletype offset rtp+=~/.vim/bundle/Vundle.vimcall vundle#begin()&quot;------------- 插件列表 ---------------------------&quot;插件设置和vim基本设置单独放置Plugin &apos;gmarik/Vundle.vim&apos;Plugin &apos;itchyny/lightline.vim&apos;Plugin &apos;scrooloose/nerdtree&apos;Plugin &apos;ctrlpvim/ctrlp.vim&apos;Plugin &apos;tacahiroy/ctrlp-funky&apos;Plugin &apos;majutsushi/tagbar&apos;Plugin &apos;taglist.vim&apos;Plugin &apos;basepi/vim-conque&apos;Plugin &apos;Valloric/YouCompleteMe&apos;Plugin &apos;Raimondi/delimitMate&apos;Plugin &apos;scrooloose/syntastic&apos;Plugin &apos;jiangmiao/auto-pairs&apos;Plugin &apos;tpope/vim-commentary&apos;Plugin &apos;sjl/gundo.vim&apos;Plugin &apos;Lokaltog/vim-easymotion&apos;Plugin &apos;tpope/vim-fugitive&apos;&quot; pythonPlugin &apos;kevinw/pyflakes-vim&apos;Plugin &apos;hdima/python-syntax&apos;Plugin &apos;pep8&apos;Plugin &apos;tell-k/vim-autopep8&apos;Plugin &apos;python.vim--Vasiliev&apos;Plugin &apos;hynek/vim-python-pep8-indent&apos;&quot; phpPlugin &apos;shawncplus/phpcomplete.vim&apos;Plugin &apos;joonty/vim-phpqa&apos;&quot; golangPlugin &apos;fatih/vim-go&apos;Plugin &apos;dgryski/vim-godef&apos;Plugin &apos;nsf/gocode&apos;, &#123;&apos;rtp&apos;: &apos;vim/&apos;&#125;&quot; markdownPlugin &apos;plasticboy/vim-markdown&apos;&quot; 多光标Plugin &apos;terryma/vim-multiple-cursors&apos;&quot; 快速注释Plugin &apos;scrooloose/nerdcommenter&apos;&quot; 对齐线Plugin &apos;nathanaelkane/vim-indent-guides&apos;&quot; 全局搜索Plugin &apos;rking/ag.vim&apos;&quot; 跳转到上次修改的地方Plugin &apos;vim-scripts/last_edit_marker.vim&apos;&quot; powerlinePlugin &apos;powerline/powerline&apos;&quot; gitgutterPlugin &apos;airblade/vim-gitgutter&apos;&quot; gitvPlugin &apos;vim-scripts/gitv&apos;call vundle#end()filetype plugin indent on 打开vim，运行:PluginInstall或在shell中直接运行vim +PluginInstall +qall即可安装插件 快捷键笔者设置的vim快捷键如下: key 作用 ,g tagbar ,n nerdtree w[hjkl] 分屏切换 gt 切换tab (文件名上面)(v/Enter) 在(新的/当前)分屏中打开文件 ,q 关闭对应分屏，退出不保存 ,w 关闭并保存 kj insert to normal ,cc 注释 ,cu 取消注释 :vs 纵向切屏 :sp 横向切屏 ,s 语法错误信息 ;/SHIFT+; nornal切换到命令行模式 H/SHIFT+右箭头 行首 L/SHIFT+左箭头 行尾 ,p 打开文件搜索栏 ,jd 跳转到变量定义处 F8 按PEP8标准格式化文件 :Ag create_order –python 全局搜索”create_order” ‘. 移动光标到上一次的修改行 `. 移动光标到上一次的修改点 `` last jump CTRL+O go back CTRL+I go forwards control+y/g’Z 可跨文件跳转到上次修改位置(last_edit_maker提供功能) :new/e/vs/sp/tabe filename 新建/当前tab/纵向/横向/新tab 打开 filename CTRL+c &amp; COMMAND+v vim复制，主机粘贴 COMMAND+c &amp; CTRL+v 主机复制，vim粘贴 ,a insert模式下php文件autocomplete，由phpcomplete的 inoremap而来 ,gs 显示文件的git更改,类似于git diff命令的显示效果 :Gitv 显示项目版本库的更改，类似于tig的效果 :Gblame 在git项目中查看每行最后的更改情况 :Phpcs run code sniffer(代码规范检查, 要求太严格，推荐不用) :Phpmd run mess detector (will ask for a rule XML file if not set，推荐不用)]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务发布经验]]></title>
    <url>%2F2016%2F12%2F01%2Fabout_deploy%2F</url>
    <content type="text"><![CDATA[发布前发布前的checklist需要包括以下内容 基础服务依赖 应用服务器资源，基础服务资源(db/redis/rmq)需要提前申请。首次上线需要提前联系运维初始化机器 MySql: 需要提前建库，建表，变更字段等 Redis: 需要提前计算容量并确认 rmq: 需要提前申请账号，确认exchange，queue等是否建立，是否需要提前bind SOA服务和接口依赖 依赖服务的集群配置。需要估算请求依赖服务的QPS，和依赖服务owner确认调用集群，确认对方服务是否已经上线 需要提前发发布计划通知调用方和被调用方 上线服务本身配置 服务配置中心上对应的配置是否已经设置 对应的业务开关/灰度开关是否在正确位置 发布系统中对应的配置是否正确 集成测试/回归测试是否正确无误 其他 至少需要一台生产环境机器登陆权限。有可能需要登陆服务器检查服务是否完全正常运行以及不正常运行的原因(日志收集服务有可能不太稳定，可能需要在生产环境进行一些操作和查询，虽然这样不太合理) 发布中基本原则: 所有的发布异常先恢复正常再修复发布问题 发布中需要确认以下事情: 发布时间一般都是避开高峰期。紧急情况在高峰期发布是否可行 发布是否有先后顺序（服务依赖，接口依赖等） 发布时需要通知NOC，方便NOC进行监控和汇集，以便出现问题时知道大概这个时间点有哪些发布 发布时的灰度很重要 每个group至少应该有一台机器独立出来作为灰度机器，每次发布先发这台机器并观察 较大改动前先提前发灰度机器并观察一段时间 发布的合理步长(每次发布一个group里面的多少台机器)为一个group的1/8-1/4，保证发布平滑 发布时需要监控如下内容: 对业务主流程是否有影响 对其他服务是否有影响 和本次发布相关的一些技术指标，业务指标等 有异常第一时间回滚或者关闭功能开关，再查找原因(important)。 发布后 需要校验相关功能已经正确执行 回复对应发布邮件通知各相关方已经正确发布]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>devops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[技术人员招聘指南]]></title>
    <url>%2F2016%2F11%2F14%2Finterview%2F</url>
    <content type="text"><![CDATA[本文主要为技术人员的招聘提供一些建议及指南，主要包括面试的流程，内容及面试评定准则。 一些原则 找出应聘者闪亮的地方 技术上的亮点等 如何获得知识 比 知道什么 重要 学习能力很重要 基础知识 比 操作技能 更重要 扎实的理论比经验性的东西更重要，九层之台，起于累土 从一个简单的问题开始，从广度和深度上不断地跟进这个问题 需要知道应聘者的能力边界在哪里 思路和方法 比 答案 更重要 简历筛选需要从简历的内容上判断应聘者的技术技能,项目经历，工作经历是否和部门的需求相符。 具有以下特点的人可能会比较符合我们的要求: 有大型/一线互联网公司工作经验的人 有电商/O2O公司工作经验的人 技术栈和我们比较匹配，或者能弥补部门技术短板的人 电话面试对于简历比较符合我们需求，但是没有条件进行当面面试的人，可以考虑先进行一轮电话面试。电话面试的主要目的在于对应聘者有一个综合的了解，而不应扣细节。可以: 对应聘者简历中描述的内容进行一些确认 对应聘者简历中未提及的技术点进行一些询问以加强对应聘者技术能力的了解 对应聘者综合素质进行一些判定 电话面试推荐不要超过两轮，并且需要在电话面试后确认是否需要约应聘者进行当面面试。 面试内容以下是当面面试时的一些内容和一些参考问题，一面和二面可以分别从中抽取一些问题询问。题目后面有标注题目的难度，分别对应P4,P5,P6级别(一些问题需要根据回答的深度区分p5/p6） 基础及理论部分 语言基础(python/java/c) python: 元类的概念及使用(p5) 生成器，迭代器(p4) 环境管理(virtualenv,pip)(p4) GIL产生的原因，对python并发的限制等(p5) 装饰器概念，使用场景，代码编写(p4) monkey patch的使用(p5) 描述Python的垃圾回收机制(p5) 引用计数 标记-清除机制 分代技术 java: collection, reflection, IOC, AOP, GC, classloader，Concurrency, generics, spring 解释IoC和DI(p4),实现(p5) 内存分配: 栈，堆，静态区(p4) 内存分配的原则 堆内存分块(p5) 新生代 老年代 永久代 Vector/ArrayList/LinkedList的区别(p4) SpringBean的加载过程 AOP的实现(p5) 代理(p4), 动态代理(p5), jdk动态代理和cglib动态代理(p6) GC机制, MinorGC &amp; Full GC区别(p5), java内存泄漏场景(p5) 类加载机制(p5) 反射的使用(p5) Thread Dump(p5) jvm常用命令jmap,jstack等(p5), jvm调优(根据情况) php 了解的php魔术方法和变量，作用(p4) 使用过的框架及其优缺点(p5+) php safe_mode的含义及影响(p5) php代码优化经验: xdebug, apc, eAccelerator, Xcache, Zend opt, C扩展等(p5) php标准库(SPL)的使用经验(p5) php代码的执行过程: zend engine, opcode(p5), sapi生命周期(p+) php弱类型是如何实现的(p6), zval(变量结构体)各字段含义及作用(p6) php hashtable作用(p5)，实现(p6)，hash碰撞及常用hash算法(p5) php gc机制(p5) php扩展编写(p6) php工作/运行模式(cgi, fast-cgi, cli, mode_php)大致描述(p4)，request/response流程(p5) C: 指针，内存管理(p5) 编码能力 Error和Exception的概念，使用姿势(p5) 序列化(p4) wordcount程序 正则表达式相关(p4) JIT概念，优点(p5) 编码解决生产者/消费者问题（p5） 实现阻塞队列(p6) 序列化和反序列化的作用，实现(p5) 死锁代码编写(p5) 并发 pid,ppid,pgid,sessionid含义(p5) Thread的sleep和object的wait方法的区别(java)(p5) 线程安全(同步/锁机制)(p5) ThreadLocal概念(p4)，使用(p5)，实现(p6) 协程(p5) 线程状态及转变(p4),线程池的使用(p5),线程池的设计(p6) 三个线程T1,T2,T3,怎样确保顺序执行(p5) join 守护进/线程的含义，作用(p5)及实现(p6) 守护进程 fork;父进程退出;子进程继续执行，成为init进程的子进程(p6) 进程/线程setDaemon作用，使用场景(p5) 网络 OSI网络模型(p4), 各分层及其作用(p5) 序列化和反序列化的作用，实现(p5) 三次握手/四次挥手(p4) http cookie/session(p4) post/get/put/delete(p4) restful(p5) http/https区别(p4) cgi/fastcgi/wsgi/servlet作用，原理，区别(p5) socket编程 tcp echo server(p4),多线程/进程echo server(p5), 多路复用echo server(p6) 进程间通信方式(p5) 管道 信号 消息 共享内存 信号量 socket 数据结构 数组，链表，队列，栈，树，堆，图 输出Fibonacci数列(p4) 队列/栈区别(p4) 如何判断链表是否有环(p5) 链表和数组的区别(存储，查找，删除等)(p4) 哈希冲突的处理方法（线性探测，二次哈希等，哈希算法）(p5) 交叉链表求交点(p5) 广度/深度优先遍历二叉树，前中后序遍历(p4) 操作系统 IO模型 同步/异步，阻塞/非阻塞(p4) select/poll/epoll区别,过程(p5) 进程调度 进程调度算法(先来先服务，短作业优先，最高优先权调度等)(p4) 僵尸进程/孤儿进程概念(p5) 死锁的产生及避免(p5) 程序预处理，编译，汇编，链接过程/内容(p4) 静态链接/动态链接(p4) 内存的分页/分段(p4) shell 使用shell求uv/pv(p4) 查找所有包含’python’的进程并kill(p4) 设计模式 代码实现单例模式 MVC模式 观察者模式 不同设计模式的使用场景(p4), 实现(p5) 数据库 ACID(p4) 数据库不同隔离级别(p4), 举例(p5) 脏读/不可重复读/幻读概念(p4)，场景(p5) undo/redo log概念(p5), 作用原理(P6) 事务(p4) 乐观锁/悲观锁概念，使用(p5)，读/写锁，表/行锁 sql注入(p4) 索引以及索引的实现(p5) 数据库操作的瓶颈及优化(p5) 版本管理 svn/git常用命令(p4) git flow工作流(p4) 算法 各种排序算法描述/编码/时(空)间复杂度 插入，选择，归并，快速，堆，冒泡排序等(p5) 查找算法 二分查找，二叉树查找等(p4) 项目及实践部分 项目经验 担任角色，项目内容，项目难点，项目优化等 对于测试驱动开发的理解 技能广度 框架，中间件(db,cache,mq)，存储(关系型/NoSQL) db/cache数据一致的保证 数据库sharding的实现，经验 消息队列的使用场景 RPC和消息的区别，适用场景 技能深度 微服务timeout设置的意义 源码，bug，坑 性能优化的经验描述 Devops ci, docker 故障定位的经验: 过程及改进措施(p5) 微服务 &amp; 架构 幂等概念(p5)，不同的实现方式(p6) 无状态含义 RPC框架设计(p6), RPC框架实现(p6) 服务注册/配置(p5) 监控/trace/报警 监控的设置(p5) trace系统原理(p6) 降级，限流，熔断，补偿，负载均衡，容量评估 微服务架构的分布式事务解决方案(p6) 补偿型（TCC） 异步确保型（可靠消息最终一致） 最大努力通知型 设计 开闭原则，MVP, KISS, Design For Failure，CAP(BASE)，DDD 什么是领域模型，什么是事务脚本？贫血模型/充血模型的区别(p6) 大型网站架构应该考虑的问题(p5) 分层 分割 分布式 集群 缓存 异步 冗余 延时任务的实现 综合部分主要考查应聘者的反应能力，学习能力，个人态度等 面试评定面试完成后，面试官需要对应聘者给出评价，多个面试官沟通后需要给出结论是否通过，并给出对应的技术评级（参考打怪升级指南）。 参考 我是怎么招聘程序员的 再谈“我是怎么招聘程序员的”（上） 再谈“我是怎么招聘程序员的”（下） 软件人员招聘]]></content>
      <categories>
        <category>management</category>
      </categories>
      <tags>
        <tag>management</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于灾备]]></title>
    <url>%2F2016%2F11%2F02%2Fdisaster_recovery%2F</url>
    <content type="text"><![CDATA[形式为了保证业务的高可用，需要保证关键业务做好灾备。 网站灾备方案不但承担容灾的任务，很多时候也承担着负载均衡，优化性能的任务。网站灾备有以下几种方式。 主备镜像(冷备)两个数据中心服务器部署完全一样，每次网站发布都要在两个数据中心同时发布，保证运行系统版本一致。两个数据中心有主备之分，数据通过准实时的同步系统从主站不断同步到备站。主站发生灾害性故障导致完全不可用，则将域名解析切换到备站。这种方案纯粹是为了容灾。 业务互补，数据同步如某网站美国机房和国内机房部署的服务在业务上互补，美国机房部署买家服务，国内机房部署卖家服务，海外用户（主要是买家）访问美国机房，国内用户（主要是卖家）访问国内机房。主要业务数据互相实时同步，因为数据在两个机房同时写入，可能会发生冲突。 主主镜像(多活)部署和发布模式与主备一样，但是多个数据中心是同时启用的，根据用户地域将域名解析到不同的机房，数据实时同步。如新浪微博。 如北方用户访问北京机房，南方用户访问上海机房。主要业务数据互相实时同步。 一写多读(类似于DB单master多slave)数据写入只发生在一个数据中心，但是为了加快地区用户访问，会将数据同步到其他数据中心供只读访问。这种方案适用于读多写少的网站。比如wikipedia。 本文讨论主备镜像形式的灾备。 流程(主备镜像)灾备对应的流程如下: 关键点数据灾备灾备的重点在于数据，即灾难发生后可以确保用户原有的数据不会丢失或者遭到破坏。解决方案是依赖基于网络的数据复制工具，实现生产中心和灾备中心之间的异步/同步的数据传输 数据灾备包括DB, rmq, cache的灾备 DB的灾备依赖DB的主从复制实现 由于架构设计时rmq不建议使用在关键链路，并且应该提供对应的业务补偿，所以不考虑同步rmq的数据 关键链路中cache只允许使用作缓存，所以不需要考虑同步数据 应用灾备应用灾备是把应用处理能力再复制一份，也就是在异地灾备中心再构建一套支撑系统。应用灾备能提供应用接管能力，即在生产中心发生故障的情况下，能够在灾备中心接管应用，从而尽量减少系统停机时间，提高业务连续性。 注意点 由于应用灾备可能并未覆盖全路径，所以灾备环境调用未部署服务时需要做容错/降级处理 数据同步的技术多种多样，即可以基于存储阵列的复制软件实现，比如EMC MirrorView、H3C Replication等，也可以基于服务器或者应用软件实现，比如Veritas VVR、Oracle DataGuard等。但不管采用何种技术，都只是在不同的层面实现了数据的同步，要具备应用接管，还需要其他组件的配合，比如DNS域名切换解析、备用网络启用、应用服务切换等等。 cache未做数据同步时，在生产流量切换到灾备时，为了防止灾备所有流量打到DB，可能需要在流量切换前做cache预热 数据表冲突的防止。在做DB切换时，需要防止主键冲突，因此auto_increment的字段需要调整自增因子等 应用服务集群切换可以在服务注册中心处理 切换至冷备机器时，对于有状态的数据，需要在切换前修复数据状态；对于需要事件驱动状态向前的数据，需要复现事件或者手动推动状态向前。总而言之，要保证切换到灾备后，状态机(业务流程)在任何点中断时，系统能够推进状态机走到终态(important) 需要考虑跨机房数据延时问题（以及由此造成的一系列数据问题），需要容忍数据丢失，并为数据延时考虑相应的对策]]></content>
      <categories>
        <category>arch</category>
      </categories>
      <tags>
        <tag>arch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务架构的分布式事务解决方案]]></title>
    <url>%2F2016%2F10%2F25%2Fdistributed-transaction-in-soa%2F</url>
    <content type="text"><![CDATA[补偿型 异步确保型 最大努力通知型]]></content>
      <categories>
        <category>arch</category>
      </categories>
      <tags>
        <tag>arch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[延时任务]]></title>
    <url>%2F2016%2F10%2F10%2Fdelay_task%2F</url>
    <content type="text"><![CDATA[背景应用中都有延时任务的需求，需要任务在指定的时间之后执行，这里讨论一下延时任务的技术实现。 实现方式实现方式主要有以下几种: rabbitmq + dead letter exchange或者rabbitmq + exchange plugin: x-delayed-message。利用queue的x-message-ttl控制消息延时时间 DB轮询。将task存储在DB中，并设置task的执行时间，同时轮询DB取出当前需要执行的task执行。优点是可结合DB事务，缺点是可能存在单点问题 rabbitmq存储task，consumer延时处理。consumer端sleep N秒。当N较大时，mq中可能会堆积大量消息 使用beanstalkd, nsq等天生很好支持延时特性的queue，但是使用较少，社区缺少相应的技术支持 dead letter exchange此处介绍一下DLX的创建, DLX的整体流程如下: 1delay_exchange =&gt; delay_queue =&gt; biz_exchange =&gt; biz_queue 创建流程如下: 创建延时exchange: delay_exchange 创建延时queue: delay_queue 设置延迟时间: x-message-ttl 设置消息到达expire时间后转到的exchange: x-dead-letter-exchange，需要为真正的业务exchange(biz_exchange) 设置delay_queue和delay_exchange的绑定 创建业务exchange: biz_exchange 创建业务queue: biz_queue 设置biz_exchange和biz_queue的绑定 此时发送到delay_exchange的消息，会在x-message-ttl设置的时间后，经过delay_queue转到biz_exchange，即到biz_queue里面。]]></content>
      <categories>
        <category>arch</category>
      </categories>
      <tags>
        <tag>arch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息补偿]]></title>
    <url>%2F2016%2F09%2F29%2Fmq_back_up%2F</url>
    <content type="text"><![CDATA[Design For FailureDesign For Failure的核心思想在于: 容忍错误，快速恢复，将failure当做普通事件处理。 当应用构建在云服务(cloud)上，这个概念更多被提及(Design For Failure Is Key To Success In The Cloud)。因为相比普通线上环境，云设施的复杂度更大，同时也导致了稳定性以及健壮性的复杂，因此Failure在云环境需要被当做普通事件处理。最佳实践可参考The Netflix Simian Army 同时对于正常环境，Design For Failure的设计思想在保证服务的健壮性，可用性上也大有裨益。 饿了么订单系统在Design For Failure思想上的实践主要有以下四个内容。第一是消息广播补偿，第二是主流程补偿，第三是灾备，第四是随机故障测试系统。 本文详细介绍一下消息广播补偿 补偿方案补偿方案可以考虑: 不同介质的补偿，如mq/redis互相补偿 不同交互方式的补偿，如push/pull结合的补偿 失败操作的Retry补偿 记录操作状态，轮询失败状态补偿 为了保证消息的高可用，将发送的消息同时存储到另外一种介质。出于性能和吞吐量上的考虑，此处考虑选择使用redis。rabbitmq发送消息时，同时保存对应routing_key的订单号到redis对应的zset中，并提供接口在rabbitmq异常时查询一定时间段内对应routing_key的订单号 存储方案由于发送的消息均有一个routing_key(订单状态转变时发送对应routing_key的订单)，所以在存储时应该将消息以routing_key分类存放。考虑将order_id存储在以routing_key为key的zset中，同时以创建时间的时间戳作为zset的score，方便获取指定时间内的订单号 1zadd(routing_key, int(time.time()), order_id) 容量计算由于每个订单的生命周期发出的消息平均约为5条，如订单的峰值TPS为1000，订单号为18位，需要提供查询半个小时之内的消息，根据解决方案可知需要至少存储1小时的内容，则需要的内存为 13600 * 1000 * 18 * 5 / 1024 / 1024 = 309M 查询接口同时需要提供查询接口查询一段时间内对应routing_key的订单号，对应接口定义如下: 123map&lt;string, list&lt;i64&gt;&gt; get_mq_order_ids(1: list&lt;string&gt; routing_keys, 2: Timestamp from_datetime, 3: Timestamp to_datetime)]]></content>
      <categories>
        <category>arch</category>
      </categories>
      <tags>
        <tag>arch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据的逻辑结构和存储结构]]></title>
    <url>%2F2016%2F09%2F10%2Fdata_structure%2F</url>
    <content type="text"><![CDATA[逻辑结构逻辑结构是指数据元素之间的逻辑关系，即从逻辑关系上描述数据。它与数据的存储无关，是独立于计算机的。数据的逻辑结构分为线性结构和非线性结构，线性表是典型的线性结构；集合、树和图是典型的非线性结构。 数据的逻辑结构分类见图。 集合结构中的数据元素之间除了 “同属于一个集合”的关系外，别无其他关系。 线性结构结构中的数据元素之间只存在一对一的关系。 树形结构结构中的数据元素之间存在一对多的关系。 图状结构或网状结构结构中的数据元素之间存在多对多的关系。 存储结构存储结构是指数据结构在计算机中的表示（又称映像），也称物理结构。它包括数据元素的表示和关系的表示。数据的存储结构是逻辑结构用计算机语言的实现，它依赖于计算机语言。 数据的存储结构主要有：顺序存储、链式存储、索引存储和散列存储。 顺序存储：把逻辑上相邻的元素存储在物理位置上也相邻的存储单元里，元素之间的关系由存储单元的邻接关系来体现。其优点是可以实现随机存取，每个元素占用最少的存储空间；缺点是只能使用相邻的一整块存储单元，因此可能产生较多的外部碎片。 链式存储：不要求逻辑上相邻的元素在物理位置上也相邻，借助指示元素存储地址的指针表示元素之间的逻辑关系。其优点是不会出现碎片现象，充分利用所有存储单元；缺点是每个元素因存储指针而占用额外的存储空间，并且只能实现顺序存取。 索引存储：在存储元素信息的同时，还建立附加的索引表。索引表中的每一项称为索引项，索引项的一般形式是：（关键字，地址）。其优点是检索速度快；缺点是增加了附加的索引表，会占用较多的存储空间。另外，在增加和删除数据时要修改索引表，因而会花费较多的时间。 散列存储：根据元素的关键字直接计算出该元素的存储地址，又称为Hash存储。其优点是检索、增加和删除结点的操作都很快；缺点是如果散列函数不好可能出现元素存储单元的冲突，而解决冲突会增加时间和空间开销。]]></content>
      <categories>
        <category>foundation</category>
      </categories>
      <tags>
        <tag>foundation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AB Test]]></title>
    <url>%2F2016%2F09%2F05%2Fab-testing%2F</url>
    <content type="text"><![CDATA[基本概念关于A/B测试所谓A/B测试，简单来说，就是为同一个目标制定两个方案。让一部分流量使用A方案，另一部分流量使用B方案。并对比两个方案的最终运营数据，看哪个方案更符合设计目标。 A/B测试的大致流程如下: 从图中可以看出A/B测试的四个关键角色: 客户端(Client) 服务器(Server) 数据层(Data) 数据仓库(Data Warehouse) 以及三种访问形式: 无A/B测试的普通访问流程(Non AB test) 基于后端的A/B测试访问流程(Back-end AB test) 基于前端的A/B测试访问流程(Front-end AB test) 关键技术A/B Test的关键在于”分流”。从上图中我们可以看到，分流可以在客户端做，也可以在服务器端做。由于PTS部门项目均位于服务层，所以我们选择在SOA层(服务端)进行分流 A/B Testing &amp; 灰度分布 &amp; 多变量测试 AB test是一种灰度发布方式，比较注重两种方案之间的测试比较。重点是在几种方案中选择最优方案 灰度测试一般是在已有产品功能升级上的测试比较。是对某一产品的发布逐步扩大使用群体范围，也叫灰度放量 多变量测试(Multivariate Testing)，和A/B Test的区别在于多变量测试涉及到多种场景的比较，其中的变量有多个，而A/B Test通常只有一个变量。 功能模块设计及实现分流模块分流开始于Dispatcher(请求入口)，分流粒度为接口级别，使用装饰器将满足特定条件的请求 从被装饰的接口(A)分流至新的接口(B) 或者使用不同参数请求原接口 工作流程如下: 请求 =&gt; 解析分流规则 =&gt; 分流 规则管理模块用于对分流维度和规则进行管理和解析。 分流维度 city_id rst_id user_id order_id 分流规则 范围分流(range) 百分比分流(percent) 特定规则分流(based on split function) 特定值分流(huskar configs) 分流规则解析模块分流规则体现在装饰器的参数中。解析模块用于对分流规则进行解析，将符合条件的请求分流 统计及展示模块暂不考虑统计模块及展示模块的设计，运营数据的对比暂时由开发拉取数据进行分析（如果有需要的话，二期吧。。。） 使用方法@split(func_name, func_get_element, rule, value, [*args, **kwargs]) func_name: 分流函数名 func_get_element: 获取分流维度的函数 分流维度可能包含以下方面: city_id rst_id user_id order_id order_mode is_book … 此处定义函数表示如何从原接口参数中计算出分流的维度 rule: 分流规则 range percent function huskar value: 特定分流规则对应值，示例如下 range: 1 - 100 percent: 20 function: 自定义function，返回值为True的请求将被分流 huskar: huskar配置中的值 *args, **kwargs: 请求参数 请求的新参数 注意事项 A/B Test分流粒度为接口级别，分流结束后需要将流量导流至最终选择的接口]]></content>
      <categories>
        <category>middleware</category>
      </categories>
      <tags>
        <tag>middleware</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[machine-learning-tutorial]]></title>
    <url>%2F2016%2F08%2F30%2Fmachine-learning-tutorial%2F</url>
    <content type="text"><![CDATA[Overview定义机器学习研究的是计算机怎样模拟人类的学习行为，以获取新的知识或技能，并重新组织已有的知识结构使之不断改善自身。通过机器学习算法，计算机从数据中自动分析获得规律(模型)，并利用规律(模型)对未知数据进行预测。 运用分类问题根据数据样本上抽取出的特征，判定其属于有限个类别中的哪一个，如 垃圾邮件识别 车牌识别 回归问题根据数据样本上抽取出的特征，预测一个连续值的结果 餐厅出餐时间预测 聚类问题根据数据样本上抽取出的特征，让相近/相关的样本聚集在一起。比如： 用户群体划分 用户画像 Learning StyleSupervised Learning 这类问题中，给定的训练样本中，每个样本的输入x都对应一个确定的结果y，我们需要训练出一个模型(数学上看是一个x→y的映射关系f)，在未知的样本x′给定后，我们能对结果y′做出预测。 这里的预测结果如果是离散值(很多时候是类别类型，比如邮件分类问题中的垃圾邮件/普通邮件，比如用户会/不会购买某商品)，那么我们把它叫做分类问题(classification problem)；如果预测结果是连续值(比如房价，股票价格等等)，那么我们把它叫做回归问题(regression problem)。 有一系列的机器学习算法是用以解决监督学习问题的，比如最经典的用于分类问题的朴素贝叶斯、逻辑回归、支持向量机等等；比如说用于回归问题的线性回归等等。 Unsupervised Learning 有另外一类问题，给我们的样本并没有给出『标签/标准答案』，就是一系列的样本。而我们需要做的事情是，在一些样本中抽取出通用的规则。这叫做『无监督学习』。包括关联规则和聚类算法在内的一系列机器学习算法都属于这个范畴。 Semi-Supervised Learning 这类问题给出的训练数据，有一部分有标签，有一部分没有标签。我们想学习出数据组织结构的同时，也能做相应的预测。此类问题相对应的机器学习算法有自训练(Self-Training)、直推学习(Transductive Learning)、生成式模型(Generative Model)等。 Reinforcement Learning 在这种学习模式下，输入数据作为对模型的反馈，不像监督模型那样，输入数据仅仅是作为一个检查模型对错的方式，在强化学习下，输入数据直接反馈到模型，模型必须对此立刻作出调整。常见的应用场景包括动态系统以及机器人控制等。常见算法包括Q-Learning以及时间差学习（Temporal difference learning）。 Algorithms(Grouped By Similarity)回归算法(Regression Algorithms) 回归算法是一种通过最小化预测值与实际结果值之间的差距，而得到输入特征之间的最佳组合方式的一类算法。对于连续值预测有线性回归等，而对于离散值/类别预测，我们也可以把逻辑回归等也视作回归算法的一种，常见的回归算法如下： Linear Regression(回归问题) Logistic Regression(分类问题) 基于实例的算法(Instance-based Algorithms) 最后建成的模型，对原始数据样本实例依旧有很强的依赖性。这类算法在做预测决策时，一般都是使用某类相似度准则，去比对待预测的样本和原始样本的相近度，再给出相应的预测结果。常见的基于实例的算法有： k-Nearest Neighbour (kNN)(分类问题) 决策树类算法(Decision Tree Algorithms) 决策树类算法，会基于原始数据特征，构建一颗包含很多决策路径的树。预测阶段选择路径进行决策。常见的决策树算法包括： Conditional Decision Trees(分类问题) 贝叶斯类算法(Bayesian Algorithms) 指的是在分类和回归问题中，隐含使用了贝叶斯原理的算法。包括： Naive Bayes(分类问题) 聚类算法(Clustering Algorithms) 把输入样本聚成围绕一些中心的『数据团』，以发现数据分布结构的一些规律。常用的聚类算法包括： k-Means(聚类问题) 关联规则算法(Association Rule Learning Algorithms) 关联规则算法是这样一类算法：它试图抽取出，最能解释观察到的训练样本之间关联关系的规则，也就是获取一个事件和其他事件之间依赖或关联的知识，常见的关联规则算法有： Apriori algorithm Eclat algorithm Workflow业务需求抽象成数学问题明确我们可以获得什么样的数据，目标是一个分类还是回归或者是聚类的问题。需要在理解业务的问题上选择合适的算法模型 获取数据数据的来源；数据要有代表性，否则必然会过拟合；数据的量级以及降维等 特征预处理与特征选择特征预处理、数据清洗是很关键的步骤，往往能够使得算法的效果和性能得到显著提高。常用的方法有归一化、离散化、因子化、缺失值处理、去除共线性等。 筛选出显著特征、摒弃非显著特征，需要机器学习工程师反复理解业务。这对很多结果有决定性的影响。这需要运用特征有效性分析的相关技术，如相关系数、卡方检验、平均互信息、条件熵、后验概率、逻辑回归权重等方法。 训练模型与调优在训练的过程中调整算法的参数，使得结果变得更加优良。 模型诊断 过拟合、欠拟合判断是模型诊断中至关重要的一步。常见的方法如交叉验证，绘制学习曲线等。过拟合的基本调优思路是增加数据量，降低模型复杂度。欠拟合的基本调优思路是提高特征数量和质量，增加模型复杂度。 误差分析 也是机器学习至关重要的步骤。通过观察误差样本，全面分析误差产生误差的原因：是参数的问题还是算法选择的问题，是特征的问题还是数据本身的问题。 诊断后的模型需要进行调优，调优后的新模型需要重新进行诊断，这是一个反复迭代不断逼近的过程，需要不断地尝试， 进而达到最优状态。 欠拟合 欠拟合的原因：模型复杂度过低，不能很好的拟合所有的数据，训练误差大； 避免欠拟合：增加模型复杂度，如采用高阶模型（预测）或者引入更多特征（分类）等。 过拟合 过拟合的原因：模型复杂度过高，训练数据过少，训练误差小，测试误差大； 避免过拟合：降低模型复杂度，如加上正则惩罚项，如L1，L2，增加训练数据等。 合适的拟合 模型融合单个模型的结果不够理想，如果想得到更好的结果，需要把很多单个模型的结果融合在一起。可以想像成“再次的机器学习过程”。 上线运行模型在线上运行的效果直接决定模型的成败。 不单纯包括其准确程度、误差等情况，还包括其运行的速度(时间复杂度)、资源消耗程度（空间复杂度）、稳定性是否可接受。 Machine learning in pythonnumpy数组运算 scikit-learnscikit-learn作为一个丰富的Python机器学习库，实现了绝大多数机器学习的算法。这是针对实际应用场景的各种条件限制，对scikit-learn里完成的算法构建的一颗决策树，每一组条件都是对应一条路径，能找到相对较为合适的一些解决方法 根据问题是有/无监督学习和连续值/离散值预测，分成了分类、聚类、回归和降维四个方法类，每个类里根据具体情况的不同，又有不同的处理方法。 matplotlib非常方便的数据可视化工具 Demo一元线性回归预测披萨价格 已知的训练样本如下: 训练样本 直径（英寸） 价格（美元） 1 6 7 2 8 9 3 10 13 4 14 17.5 5 18 18 披萨价格与直径的图示如下 123456789101112import matplotlib.pyplot as pltdef runplt(): plt.figure() plt.axis([0, 25, 0, 25]) plt.grid(True) return plt plt = runplt()X = [[6], [8], [10], [14], [18]]y = [[7], [9], [13], [17.5], [18]]plt.plot(X, y, &apos;k.&apos;)plt.show() 能够看出，匹萨价格与其直径正相关。使用scikit-learn构造一元线性回归模型 123456789from sklearn.linear_model import LinearRegression# 创建并拟合模型model = LinearRegression() model.fit(X, y) # 预测其他直径披萨的价格X2 = [[0], [10], [14], [25]]y2 = model.predict(X2)plt.plot(X2, y2, &apos;g-&apos;)plt.show() 可以看出拟合出的披萨价格和直径的模型。]]></content>
      <categories>
        <category>machine-learning</category>
      </categories>
      <tags>
        <tag>machine-learning</tag>
      </tags>
  </entry>
</search>
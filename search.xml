<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[服务监控和报警]]></title>
      <url>%2F2017%2F01%2F24%2Fmonitoring_and_alerting%2F</url>
      <content type="text"><![CDATA[背景对于应用开发团队来说，每天面对大量复杂多变业务逻辑的开发。为了发现潜在的问题，为了发生突发问题进行排障时有据可循，更为了了解服务的运行状况和服务性能，一个完善的自动化的监控报警系统非常必要。 系统架构监控系统一般监控系统的系统架构包括以下方面 指标收集agent指标的数据源主要有以下几个: 代码埋点 日志 数据库 一般增加一个collect agent用于统一数据格式，收集实时指标，同时用于数据的广播，解耦系统以及快速持久化等，同时将所有的指标发送到这个agent 传输由于指标是非业务数据，属于样本性质，可以容忍丢失。所以数据源到agent的数据传输，一般使用UDP协议 分析计算需要进行分析计算的指标维度一般有以下几种: Gauges: 代表一个度量的即时值。当你的程序运行的时候，内存使用量和CPU占用率都可以通过Gauge值来度量。 Counters: 就是计数器，是一个可以用来增加或者减少值的数。例如，可以用它来计数队列中加入的Job的总数。 Meters: 用来计算事件的速率。例如 request per second。还可以提供1分钟，5分钟，15分钟不断更新的平均速率 Histograms: 可以为数据流提供统计数据。除了最大值，最小值，平均值外，它还可以测量中值(median)，百分比比如XX%这样的Quantile数据 Timers: 用来测量一段代码被调用的速率和用时 显示 &amp; 通知对应的数据在进行计算后，需要进行显示。同时若有异常情况，需要通知关注的人员。 报警系统报警系统的数据来源和监控系统相似，只是在分析计算后添加了报警规则配置和报警事件生成层 监控报警系统的系统架构可以参考: 统一监控报警平台的架构设计思路分享 技术方案 数据的采集可以使用Statsd,Collectd 数据的存储可以使用Graphite carbon守护进程，接收Statsd发送过来的原始统计数据 whisper用来存储统计数据的库 graphite webapp用来图形化展示统计数据的web项目 数据的存储也可以使用influxdb 使用Grafana对指标进行展示 报警使用kapacitor 可以对技术方案进行以下组合: TICK(telegraf + influxdb + chronograf + kapacitor) statsd + graphite + grafana + banshee(ele.me使用) 监控设置完善的监控和报警可参考如下设置 服务 &amp; 接口 关键接口调用量，失败量 关键接口耗时 关键接口异常 自定义的业务指标监控，如交易中的买家数，金额等 基础服务 DB: 具体SQL响应时间，调用量，失败量，慢SQL数等 REDIS: 对应操作响应时间，调用量，失败量，cache命中率等 RMQ: 消息ready/unack/total数，publish/get速度(参看rabbitmq management插件提供的指标)，消息堆积数量等 应用服务器 cpu load, cpu util memory util, memory swap network-in, network-out, network-speed disk io TCP connection 报警设置报警主要针对以下情况 指标趋势 如某段时间指标值快速上升或者快速下降, 同环比趋势异常等 指标阈值 如调用量超过一定值，cache miss率超过一定值等 指标特殊值 如指标为0，为空等]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[RPC(远程过程调用)和MQ(消息队列)]]></title>
      <url>%2F2017%2F01%2F23%2Frpc_and_mq%2F</url>
      <content type="text"><![CDATA[背景系统间互相调用时，是选择RPC还是MQ是经常需要权衡的问题，本文对两者的特点及适用场合进行简单的分析。 系统结构RPC系统结构12345+----------+ +----------+| Consumer | &lt;=&gt; | Provider |+----------+ +----------+Consumer调用Provider提供的服务 MQ系统结构12345+----------+ +-------+ +----------+| Producer | &lt;=&gt; | Queue | &lt;=&gt; | Consumer |+----------+ +-------+ +----------+Producer发送消息给Queue；Consumer从Queue拿消息来处理 功能特点相同点 都利于大型系统的解耦 都是用于子系统的交互和通信，特别是异构子系统的交互 RPC的特点 同步调用，是本地调用的扩展，对于要等待返回结果的场景，RPC是非常直觉的使用方式(当然RPC也可以是异步调用) 如果接口文件有变化，则Provider和Consumer都需要变更和重新部署 MQ的特点 MQ的请求和处理是异步的 MQ能够把请求暂存在broker，可以起到请求削峰的作用，Consumer可以按照自己的节奏来处理请求 MQ引入了一个新的结点(broker)，链路越长，系统的可靠性保障越低 MQ侧重数据的传输，因此方式更加多样化，除了点对点外，还有订阅发布等功能 如何选择 如果希望同步得到请求的处理结果，则选用RPC；如果基于性能的考虑，比如服务端不能快速的响应客户端（或客户端也不要求实时响应），不希望请求端受限于处理端的处理速度时，则选用MQ RPC是本地调用的扩展，使用简单；MQ的异步编程模式比较复杂 可靠性上: RPC可以通过同步调用的结果来决定是否进行补偿等操作，MQ一般不认为100%可靠。 对于有强一致性要求的场景，一般选择RPC 对于为了增加主流程性能，让其他次要流程异步操作时，可以选择MQ，如短信发送，日志记录，邮件服务，通知服务等。 如果调用侧重于点对点的功能调用，则选用RPC；如果侧重于数据的传输和广播，则选用MQ 参考 The case: RPC vs. Messaging]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[数据库sharding]]></title>
      <url>%2F2017%2F01%2F21%2Fabout_sharding%2F</url>
      <content type="text"><![CDATA[概念数据库sharding，是指通过某种条件，把同一个数据库中的数据分散到多个数据库或多台机器上，以减小单台机器压力。 关于sharding更多的知识请参考: 数据库分库分表(sharding)系列 分类和维度分类垂直sharding以表为单位，把不同的表分散到不同的数据库或主机上。按领域模型，将业务紧密，表间关联密切的表划分在一起。特点是规则简单，实施方便，适合业务之间耦合度低的系统。 水平sharding以行为单位，将同一个表中的数据按照某种条件(譬如按ID散列)拆分到不同的数据库或主机上。特点是相对复杂，适合单表巨大的系统。 维度此处以电商为例 垂直维度: 按业务领域可以划分为booking，订单，商户，支付，物流等几个领域，可按此进行垂直拆分 水平维度: 电商中的两个最重要相关业务方为买家和卖家，最重要的业务为订单，所以可以依据买家和卖家信息生成订单，同时基于买家/卖家维度对相关表进行水平拆分 sharding实现层面从一个系统的程序架构层面来看，sharding逻辑可以在DAO层、JDBC API层、介于DAO与JDBC之间的Spring数据访问封装层(各种spring的template)以及介于应用服务器与数据库之间的sharding代理服务器四个层面上实现。 迁移随着业务的发展，一般都会有一个从非sharding向sharding迁移的过程，为了保证迁移过程中数据的准确性和迁移失败的可回退，迁移过程一般分为三个阶段: 双写读非sharding(此时需要校验非sharding和sharding库的数据一致性) 双写读sharding(此时还写非sharding是为了保证出问题时可以随时回退) 写sharding读sharding(切换完成) 系统由A状态过渡到B状态（系统的迁移）是另一个比较大也比较考验水平的话题 需要注意的地方全局主键一旦数据库被切分到多个物理结点上，我们将不能再依赖数据库自身的主键生成机制。此时可能需要一个全局主键生成机制，可以参考分布式系统中的全局唯一ID 引入分布式事务的问题一旦数据被切分到多个server中，势必会引入跨库事务的问题。此时可以考虑将一个跨多个数据库的分布式事务分拆成多个仅处于单个数据库上面的小事务，并通过应用程序来总控各个小事务。或者考虑一下分布式事务的解决方案 跨节点join的问题对应的解决方案为: 不使用复杂sql，这是比较推荐的作法，互联网行业一般只推荐使用简单sql 通过应用程序来进行处理，先在驱动表所在的DB中取出相应的驱动结果集，然后根据驱动结果集再到被驱动表所在的DB中取出相应的数据。 跨节点合并排序分页问题对应的解决方案为: 在应用程序中完成对应的合并排序分页。要记住一个基本原则: 尽量避免使用数据库做运算，因为数据库是不方便扩展的，因此只建议让数据库做基本的存储和事务保证功能。而应用服务器理论上是可以无限scale out的，所以资源消耗型的计算都建议由DB数据器移到应用服务器 使用搜索引擎解决。搜索引擎和CACHE实际都是DB功能的扩展，使用搜索引擎是很好地提高DB性能和弥补DB缺陷的手段 数据热点问题电商网站按买家ID分片的时候各分片间数据基本分布均匀，但是按卖家ID分片的时候由于可能存在热点卖家的问题，此时可能出现数据在某些分片集中，可以对热点分片考虑再分片。 迁移过程非sharding和sharding数据不一致由于各种原因，可能存在此问题。这是在迁移过程中需要解决的问题，只有两者数据一致时迁移第一阶段才算完成 多维度sharding数据不一致电商行业普通采用买家和卖家两维度的分片，此时由于两维度数据的提交不在同一个事务中，所以可能存在分布式事务的问题。为了保证两维度数据一致，可以考虑对另一维度的数据进行补偿（不考虑比较复杂的两阶段提交）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[分布式系统中的全局唯一ID]]></title>
      <url>%2F2017%2F01%2F20%2Fglobal_id%2F</url>
      <content type="text"><![CDATA[在分布式系统中，生成全局唯一ID的需求很常见。生成的方法主要有基于数据库生成，使用分布式集群协调器和划分命名空间并行生成等。 常用技术方案基于数据库生成这种类型的生成方案，都可以设置其初始值以及增量步长，一般包含以下几种: 使用mysql auto_increment特性 使用postgresql sequence特性 使用oracle的sequence特性 为了避免数据库的单点故障，还可以使用多台数据库服务器使用不同的步长来生成ID 各种基于数据库的全局唯一ID生成方案可以参考: http://www.cnblogs.com/heyuquan/p/global-guid-identity-maxId.html 基于分布式集群协调器生成在不使用数据库的情况下，通过一个后台服务对外提供高可用的、固定步长标识生成，则需要分布式的集群协调器进行。 一般的，主流协调器有两类： 以强一致性为目标的：ZooKeeper为代表 以最终一致性为目标的：Consul为代表 ZooKeeper的强一致性，是由Paxos协议保证的；Consul的最终一致性，是由Gossip协议保证的。 在步长累计型生成算法中，最核心的就是保持一个累计值在整个集群中的「强一致性」。但是，这也会为唯一性标识的生成带来新的形成瓶颈。 划分命名空间并行生成似乎对于分布式的ID生成，以Twitter Snowflake为代表的， Flake 系列算法，经常可以被搜索引擎找到，但似乎MongoDB的ObjectId算法，更早地采用了这种思路。 snowflake是Twitter开源的分布式ID生成算法，结果是一个long型的ID。其核心思想是：使用41bit作为毫秒数，10bit作为机器的ID（5个bit是数据中心，5个bit的机器ID），12bit作为毫秒内的流水号（意味着每个节点在每毫秒可以产生 4096 个 ID），最后还有一个符号位，永远是0。snowflake算法可以根据自身项目的需要进行一定的修改。比如估算未来的数据中心个数，每个数据中心的机器数以及统一毫秒可以能的并发数来调整在算法中所需要的bit数。 我的Global Id用于标识电商网站订单号 特性 12-19位int类型。方便用户阅读使用，同时数据库长整数字型的数据索引与检索效率，远远高于文本型。(Java long型对应 2 ^ 64为20位10进制型，所以也在long范围内) 需要标识业务/技术属性 业务属性 订单类型，如实物商品/虚拟商品 外卖订单/团购订单 … 技术属性 IDC归属 测试订单 … 考虑到长度问题，不考虑包含时间因素 包含卖家/买家信息 设计1[自增部分] + [1位业务标识] + [1位技术标识] + [3位商家标识] + [3位用户标识] 自增部分用来保证订单号的唯一以及订单号的有序，使用DB自增生成 业务标识用来标识业务属性 技术标识用来标识技术属性 商户ID散列值 mod 512，可以用来做商户维度的sharding，根据笔者经验，大中型网站分片数512已经足够。同时不考虑2/10进制转换来标识sharding，也是为了阅读方便 用户ID散列值 mod 512，可以用来做用户维度的sharding 容量评估假设订单长度大于12位(后8位为标识位)，则自增的起始值为1,000。到20位时，自增值为1000,0000,0000。以1000,0000单一天计算，则订单号可以使用 1(100000000000 - 1000) / 10000000 / 365 = 27(年) 存储及使用自增的起始值存储在mysql中，使用的过程如下: 123456789101112131415161718192021queue = multiprocessing.Queue()def get_global_id(): order_id = queue.get() if order_id: // fetch from queue return order_id else: // fetch from db order_id_list = fetch_id_list_from_db() for order_id in order_id_list: queue.put(order_id) order_id = queue.get() return order_id def fetch_id_list_from_db(): db.select_for_update() // db获取悲观锁，注意此时表只有一行，所以需要通过ID获取行锁，忌使用表锁 order_ids = db.select(1000) // 一次取1000个order id db.sequence.update(1000) // db sequence 字段增加1000 db.commit() return order_ids]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[关于timeout]]></title>
      <url>%2F2017%2F01%2F16%2Fabout_timeout%2F</url>
      <content type="text"><![CDATA[使用Timeout，是一种常见的容错模式。常见的有设置网络连接超时时间，一次RPC的响应超时时间等。在分布式服务调用的场景中，它主要解决了当依赖服务出现建立网络连接或响应延迟，不用无限等待的问题，调用方可以根据事先设计的超时时间中断调用，及时释放关键资源，如Web容器的连接数，数据库连接数等，避免整个系统资源耗尽出现拒绝对外提供服务这种情况。 意义: 当网络出现短暂的抖动，或者下游服务调用超时时，合理的超时时间可以避免连接池快速被占满，可有效延长服务的可用时长 可以结合降级，熔断等SOA治理的手段使用 原理阻塞IO的timeout由于我们常用的socket都是阻塞的，那么超时是很好设置的，直接设置socket的超时就可以了。 1234// send timeoutsetsockopt(socket，SOL_S0CKET,SO_SNDTIMEO，(char *)&amp;nNetTimeout,sizeof(int));// receive timeoutsetsockopt(socket，SOL_S0CKET,SO_RCVTIMEO，(char *)&amp;nNetTimeout,sizeof(int)); 非阻塞IO的timeout但是，用过Linux下非阻塞I/O的都知道，非阻塞情况下，设置连接超时神马都是浮云的，因为人家是非阻塞的。典型的譬如Python的gevent，在用monkey.patch_all()之后，所有的socket都会被转化为非阻塞的，这时候的timeout设置就失效了。这种情况下gevent提供了Timeout类，当你的类似sleep（由于I/O、sleep等原因挂起）超时超过了Timeout的时间限制后，会自动终止block，跳出。使用方法如下: 1234567891011121314import geventimport gevent.monkeyimport timegevent.monkey.patch_all()def test(): with gevent.Timeout(5) as timeout: time.sleep(10) print &quot;time out&quot;if __name__ == &quot;__main__&quot;: g = gevent.spawn(test) g.join() zeus_core中的超时1. api_hard_timeout为接口的真实超时设置，为server的超时设置。是gevent执行对应协程时的Timeout，为server应用逻辑的timeout设置: 123456service = Service( name=NAME, slug=NAME[NAME.find(&apos;.&apos;)+1:], timeout=3 * 1000, api_hard_timeout=SERVICE_API_HARD_TIMEOUT, ... 实现: 1234with gevent.Timeout(hard_timeout): try: result = func(dispatcher, *args) ... 2. timeout为软超时，目前只是打个warning,发个signal(无实际价值)3. 调用其他服务时候的超时，为client的超时设置。是网络请求时的timeout设置: 12345678910&apos;payment&apos;: &#123; &apos;pool&apos;: &apos;huskar&apos;, &apos;name&apos;: &apos;me.ele.payment.service&apos;, &apos;client&apos;: &apos;http&apos;, &apos;timeout&apos;: config.get(&apos;config:soa_client_timeout:payment&apos;, 1), &apos;cluster&apos;: config.get(&apos;config:cluster:payment&apos;, &quot;stable&quot;), &apos;iface&apos;: &apos;me.ele.payment.api.service.PaymentService&apos;, &apos;thrift_file&apos;: path.join( current_path, &apos;thrift_files/payment/PaymentService.thrift&apos;), &#125; 表示EOS调用payment服务时的eos超时时间 实现:(参考zeus_client使用http client中的代码实现) 123456from thriftpy.transport import TSocket, TBufferedTransportfrom . import Client, THTTPJsonProtocolsocket = TSocket(host, port)socket.set_timeout(timeout)... Pylon对应的超时1234567891011121314151617181920private Object callCommand(Task task, BreakerMetrics metric) throws Throwable &#123; Future&lt;?&gt; result = null; try &#123; result = service.submit(task); long timeout = task.getTimeoutInMillis(); Object ret = result.get(timeout &gt; 0 ? timeout : property.getTimeout(), TimeUnit.MILLISECONDS); metric.increment(BreakerStatus.SUCCESS); if (metric.inTestPhase()) &#123; metric.singleTestPass(true); &#125; return ret; &#125; catch (InterruptedException | TimeoutException e) &#123; metric.increment(BreakerStatus.TIMEOUT); if (result != null) &#123; result.cancel(true); &#125; task.cancel(); task.setStatus(CallStatus.timeout); throw new RequestTimeoutException(String.format(&quot;Service(%s) occurs a request execution timeout!&quot;, property.getService()));... Java的超时设置可以参考: Java: Set timeout for threads in a ThreadPool 对应代码如下: 1234567891011121314Future&lt;?&gt; future = null;for (List&lt;String&gt; l : partition) &#123; Runnable worker = new WorkerThread(l); future = executor.submit(worker);&#125;try &#123; System.out.println(&quot;Started..&quot;); System.out.println(future.get(3, TimeUnit.SECONDS)); System.out.println(&quot;Finished!&quot;);&#125; catch (TimeoutException e) &#123; System.out.println(&quot;Terminated!&quot;);&#125; 最佳实践为了让client尽快得到响应，也为了尽量减少服务响应延迟时的服务资源消耗，需要设置client timeout(客户端timeout), server timeout(服务端timeout)以及service timeout(基础服务如mysql等timeout)。同时需要根据实际情况设置一条请求链路上对应client,server和service的timeout。 一般需要考虑以下情况: 设置client timeout保证client尽快得到响应，同时方便重试 设置server timeout保证及时释放服务器资源，保证不被client拖垮 设置一些基础服务的timeout，可以有效保护对应资源，避免整个系统资源耗尽出现拒绝对外提供服务这种情况 timeout值的考虑 一条链路上游至下游如果只是一次Request/Response的话，那么对应的timeout值应该逐渐减少，如RPC请求的Client和Server端（保证请求的时间范围覆盖了响应的时间范围） 如果有多次交互的话，无需要考虑。如server请求DB，Server先发送commit到DB，若Server超时后再发rollback给DB。则DB的timeout无需要比Server短，只需要考虑DB自身的性能即可 mysql timeout实验目的: 实验client通过RPC请求SERVER，同时操作MYSQL时相应timeout的最佳设置 背景table结构如下: 12345678&lt;resultMap id=&quot;BaseResultMap&quot; type=&quot;me.ele.fin.job.dal.model.TestModel&quot;&gt; &lt;id column=&quot;id&quot; property=&quot;id&quot; jdbcType=&quot;BIGINT&quot;/&gt; &lt;result column=&quot;restaurant_id&quot; property=&quot;restaurantId&quot; jdbcType=&quot;BIGINT&quot;/&gt; &lt;result column=&quot;order_id&quot; property=&quot;orderId&quot; jdbcType=&quot;BIGINT&quot;/&gt; &lt;result column=&quot;status&quot; property=&quot;status&quot; jdbcType=&quot;TINYINT&quot;/&gt; &lt;result column=&quot;created_at&quot; property=&quot;createdAt&quot; jdbcType=&quot;TIMESTAMP&quot;/&gt; &lt;result column=&quot;updated_at&quot; property=&quot;updatedAt&quot; jdbcType=&quot;TIMESTAMP&quot;/&gt; &lt;/resultMap&gt; 对应RPC请求接口逻辑如下: 12345678910111213141516@Transactional(timeout = 10)public int updateTestStatus(Long id) throws JobServiceException &#123; Long startTime = System.currentTimeMillis(); int updateRes = 0; try &#123; updateRes = testMapper.updateById(id); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; Long endTime = System.currentTimeMillis(); String duration = DurationFormatUtils.formatPeriod(startTime, endTime, &quot;S&quot;); logger.info(&quot;update result: &quot; + updateRes); logger.info(&quot;Duration milliseconds: &quot; + duration); return 1;&#125; mysql对应timeout设置如下: 123456789101112131415161718mysql&gt; show variables like &quot;%timeout%&quot;;+-----------------------------+----------+| Variable_name | Value |+-----------------------------+----------+| connect_timeout | 10 || delayed_insert_timeout | 300 || innodb_flush_log_at_timeout | 1 || innodb_lock_wait_timeout | 50 || innodb_rollback_on_timeout | OFF || interactive_timeout | 28800 || lock_wait_timeout | 31536000 || net_read_timeout | 30 || net_write_timeout | 60 || rpl_stop_slave_timeout | 31536000 || slave_net_timeout | 3600 || wait_timeout | 28800 |+-----------------------------+----------+12 rows in set (0.00 sec) 步骤1. 设置autocommit为OFF1set autocommit = 0; 2. 锁定某一条记录12begin;select * from test where id = 1 for update; 锁定id为1的记录 3. 调用接口，update同一条记录运行以下JUnit测试 123456789101112131415161718public class JobServiceTest extends TestBase &#123; @Autowired private IJobService ijs; /** * 测试本地服务 */ @Test public void testServiceFromLocalContext() throws JobServiceException &#123; try &#123; int returnVal = ijs.updateTestStatus(1L); Assert.assertTrue(returnVal == 1); &#125; catch (JobServiceException ex) &#123; ex.printStackTrace(); &#125; &#125;&#125; 结果及结论使用postman模拟client调用对应接口，设select for update为事务1，接口调用为事务2。 0 - 10s 内，提交事务1(运行commit手动提交), 则事务2可以获取innodb锁往下执行，最后事务2也正确提交 10 - 50s 内，提交事务1，则事务2roll back，同时立刻返回结果给client，表示@Transactional(timeout = ?)可以设置在多长时间后，应用逻辑中mysql事务失败，事务2会rollback，同时返回结果给client（快速失败） &gt;50s 后，由于innodb_lock_wait_timeout的存在，事务1和事务2都会roll back，且打印以下log 122017-01-16 14:04:23.810 INFO me.ele.fin.job.service.JobService[main]: [unknown 1.1 unknown^^2337080905338436383|1484546598112] ## update result: 0 2017-01-16 14:04:23.810 INFO me.ele.fin.job.service.JobService[main]: [unknown 1.1 unknown^^2337080905338436383|1484546598112] ## Duration milliseconds: 51288]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[关于幂等]]></title>
      <url>%2F2017%2F01%2F10%2Fabout_idempotency%2F</url>
      <content type="text"><![CDATA[幂等方案可以保证幂等的操作1. 查询操作查询一次和查询多次，在数据不变的情况下，查询结果是一样的。在隔离级别为可重复读(mysql默认隔离级别)时，select是天然的幂等操作 2. 删除操作删除操作也是幂等的，删除一次和多次删除结果相同，都是把数据删除。(注意可能返回结果不一样，删除的数据不存在，返回0；删除的数据多条，返回结果多个) 3. 唯一索引唯一索引或唯一组合索引来防止提交重复数据，不过对DB性能有影响 4. 悲观锁获取数据的时候加锁获取 1select * from table_xxx where id=&apos;xxx&apos; for update; 5. 乐观锁乐观锁只是在更新数据那一刻锁表，其他时间不锁表，所以相对于悲观锁，效率更高。 乐观锁的实现方式多种多样，可以通过version或者其他状态条件： 通过版本号实现 1update table_xxx set name=#name#,version=version+1 where id=#id# and version=#version# 通过条件限制 1update table_xxx set total=total-#hongbao# where id=#id# and total-#hongbao# &gt; 0 6. 分布式锁如果是分布式系统，构建全局唯一索引比较困难，例如唯一性的字段没法确定，这时候可以引入分布式锁，通过第三方的系统(redis或zookeeper)，在业务系统插入数据或者更新数据，获取分布式锁，然后做操作，之后释放锁。 或者在执行接口的逻辑前，先在mysql表中插入接口的特征值(此字段设置unique)，用mysql保证对应的业务逻辑只执行一次。 分布式锁的java实现及使用: https://github.com/redisson/redisson https://my.oschina.net/wangnian/blog/668830 7. 状态机幂等状态在不同的情况下会发生变更，一般情况下存在有限状态机(fsm)，这时候，如果状态机已经处于下一个状态，这时候来了一个上一个状态的变更，理论上是不能够变更的，这样的话，保证了有限状态机的幂等。 伪代码如下: 123// 如果状态已经发生变更，直接returnif fsm.status = expected_status: return 不推荐的方案1. select + insert并发不高的后台系统，或者一些任务JOB，为了支持幂等，支持重复执行，简单的处理方法是，先查询下一些关键数据，判断是否已经执行过，再进行业务处理。这种方法在高并发时会出现问题 几条基本原则 DB不能DOWN，DB不能DOWN，DB不能DOWN 这是最重要的前提。不管是使用连接池，使用缓存，使用搜索，还是DAL的限流。所有这些措施的最重要作用首先都是为了保证数据库的正常运行，防止数据库DOWN，然后才是为了提高性能 业务要保证正确 业务的正确保证不需要多言。所以为了避免插入重复数据时，DB需要设置唯一键（尽管这会降低DB性能） 性能优化是最后考虑的事 只有DB服务器正常运行，业务正确的前提下，再开始考虑优化性能 推荐方案所以在防止插入重复数据时，推荐的方案是: 使用redis作为接口锁，防止重复请求到达数据库，对数据库性能造成冲击（初步的幂等保证及数据库保护） 使用唯一键保证不插入重复数据（最后的兜底及最终保证） 处理措施 列出关键服务（交易，支付，清结算）的关键路径（接口） 确认接口是否需要保证幂等，注明现在的幂等方案，考虑是否存在隐患 第一步需要保证所有路径的业务正确，第二步使用推荐方案同时保证业务正确和高性能]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python Is Not Java]]></title>
      <url>%2F2017%2F01%2F05%2Fpython-is-not-java%2F</url>
      <content type="text"><![CDATA[语言上的差异讲述的地方很多，可以参考: Java 和 Python 有哪些区别。 这里主要是讲述一些语言风格/编程思维的对比 Python/Java风格对比1. 平铺的结构比嵌套的要好 Java中的静态方法不能翻译成Python的类方法。Java静态方法惯用的翻译通常翻译成一个模块级的函数，而不是一个类方法或静态方法。(并且静态常量应该翻译成模块级常量)。这不是性能上的问题，但是一个Python程序员如果想调用Foo.someMethod，他要是被迫采用像Java中Foo.Foo.someMethod的方式去做的话，那么他就会被逼疯的。有一点一定要注意:调用一个类方法需要一个额外的存储空间,而调用静态方法或函数就不需要这样. Python中,要记住一点,平铺的结构比嵌套的要好,尽管相对于从性能方面来说,可能它更多涉及的是”可读性”和”简单要比复杂好”。 2. 拒绝XML。比起Java代码，XML是灵活而且有弹性的。但比起Python的代码来，XML就是一个船锚，一个累赘。 如果你不是因为信息交互的原因去实现一个已经存在的XML标准或是建立某种输入、输出格式或者建立某种XML编辑器或处理工具，那么就不要在python中考虑XML 3. Getter和setter是恶魔 Python对象不是Java Bean。不要写什么getter和setter。它们是CPU时间的浪费，更要紧的是，它们还是程序员宝贵时间的浪费。 在Java中，你必须使用getter和setter,因为公共字段不允许你以后改变想法再去使用getter和setter。所以,在Java中你最好事先避开这些”家务杂事”.在Python中，这样做很傻，因为你可以以一个普通特性开始并可以在任何时间改变你的想法，而不用影响到这个类的任何客户。所以不要写getter和setter方法。 4. 代码重复在Java中通常来说就是一场不可避免的灾祸，但Python可以避免 在Python中，你写了一个包含了函数的函数。这里内部的函数就是你要一遍遍写的函数的模版，但是在里面加入了针对不同情况的函数要使用变量。外部的函数需要刚刚提高的那种变量作为参数，并且将内部的函数作为结果返回。然后，每次你要写另一种略微不同的函数的时候，你只要调用这个外部的函数，并且把返回值赋给你要让“重复”函数出现的名字。现在，如果你需要改变这个工作方式，你只需要改变一个地方：这个模版。 Java编程思维的吐槽另外转一个关于Java的吐槽，相对于Python和Java的比较也符合: 风格的问题。这个问题我认为是最严重的。基础软件开发崇尚的是自由、直接、透明、简单、高效，要像匕首一样锋利，像战士一样勇猛，像农夫一样朴实，反对繁琐华丽的设计，反对架床迭屋的层层抽象，反对复杂的结构和不必要的灵活性。而Java社群多年来形成的设计风格与此格格不入，甚至可以说是对立的。Java在意识形态上是要面向企业应用软件的开发，所以特别强调架构，强调设计模式，强调标准，强调规规矩矩，强调高姿态，强调一种华贵的宫廷气质。在C中，你吃饭就是吃饭，捧起碗来喝酒，放下筷子骂娘，甩开膀子抓肉，撸起袖子抹油。而在Java中，你经常为了要干某件事，先new一个对象，然后以这个对象为参数new另一个对象，如此这般重复n遍，得到真正需要的对象，最后就是为了调用那个对象的一个方法，就好比吃饭时焚香洗面，漱口净手，战战兢兢，毕恭毕敬。在C中，遇到问题要像亡命徒，像流氓版程咬金，管你三七二十一，冲上去就是三板斧，还怕劈不死你丫的。在Java里，遇到问题要像宋襄公，要张榜檄文，要名正言顺，要礼仪之邦，要把架子拉开了，把谱儿摆足了。Java的口号是，不管劈不劈的死，先把你小子感动了再说。 这套繁琐的东西，对于基础软件开发来说，既不必要，也很难习惯。需要说明的是，这不是Java语言的问题，其实Java本身不必如此复杂、如此巴洛克。从语言本身来看，Java也可以是轻快直接的，也可是酣畅淋漓的。只不过十多年来几乎没有人这样用过，所以大家已经不知道：如果不来个一步三叩首，那么该怎么用Java写程序？]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[基于Pylon的Demo开发及发布相关]]></title>
      <url>%2F2016%2F12%2F30%2Fjava_develop_deploy_base_on_pylon%2F</url>
      <content type="text"><![CDATA[基于pylon的服务,包括代码结构及开发流程。 sample可以参考sample-project, repo地址https://git.elenet.me/pts/sample-project 也可以参考settle项目 最好的参考项目compensation-service 代码结构 api: 接口定义相关 api: 接口定义 OrderApiService: 提供的eleme_order相关的api dto: 定义请求的数据结构和返回的数据结构(对应javabean) ElemeOrder: OrderApiService中接口需要的请求和返回数据结构 form: 也可以使用dto定义返回的数据结构，form定义请求的数据结构 注意(important): 最好不要定义form的constructor enum: 对于其中请求参数常量的使用。可以将常量定义在enum中，传递的时候使用enum实例即可，使用enum表达的信息更为丰富 exception: 接口exception定义 ServiceException: 表示业务相关的异常(如用户不存在，红包已过期等) SystemException: 表示服务内部的异常(如数据库连接超时，redis服务不可用等) java.lang.RuntimeException: 非受检异常, 计入熔断统计 其余异常参考: Pylon内置Rpc异常 dao: model定义,和DB table crud一一对应，供service中接口实现使用 ElemeOrderDao: eleme_order表对应的数据模型，和eleme_order表字段对应 resources: DB连接，DB事务等 deploy: 发布相关定义(发布相关变量等), 最终发布文件存储位置 docs: 文档 service: 接口实现,业务逻辑定义。可以加一层BIZ层, service抽象成webapi, biz写详细业务逻辑。依赖api和dao conf: 主要的配置文件 Configure.json: 最重要的配置文件。 serverConf: 服务端配置 initializer: IServiceInitializer实现类类名 interfaces: 提供服务的接口名列表 clientConfs: 客户端配置, 有依赖服务则需要声明 interfaces: 调用的接口名列表 OrderApiServiceImpl: OrderApiService中各种接口的实现 soa: 实现Pylon接口 ServiceInitializer: 服务初始化接口, 服务启动的时候调用对应init方法 getImpl: 返回指定接口对应的实现实例(所以能够通过提供的interface名找到对应的方法实现类) MainApplication: 程序启动入口, 启动基于Pylon的服务(其实是调用ServiceInitializer.init()) 。也可以通过me.ele.core.container.Container作为MainClass启动。(start.sh中配置启动入口) common: 定义公共组件 pom.xml: 父级pom定义 开发流程: 定义接口: api定义, interface定义，写对应的dto DAO层: db table crud实现 service: 业务逻辑 test: optional 发布: eless配置替换代码中配置 ci start.sh accept request 测试测试方法有以下几种: 在单元测试代码中测试 测试其他服务接口，需要构造client从huskar获取服务列表，发起RPC请求 参考me.ele.pts.sample.test.base.TestBase的定义 ClientUtil.getContext().initClients(&quot;deploy/conf/configure.json&quot;);初始化Configure.json中定义的客户端，所以可以在SampleServiceTest中直接调用TimeLineSearchService timeLineSearchService = (TimeLineSearchService) ClientUtil.getContext().getClients(TimeLineSearchService.class);构造TimelineSearchService的客户端（从alpha环境中获取配置），并调用对应接口 测试本服务接口，直接测试Service层对应接口实现代码即可。不需要通过接口调用，方便debug 参考me.ele.pts.sample.test.base.TestBase的定义 new AnnotationConfigApplicationContext(MainApplication.class);注入MainApplication中定义的Bean，所以可以在SampleServiceTest中调用SampleApi sampleService = ApplicationContextUtil.context.getBean(SampleApi.class);获取对应的Bean,直接调用对应的方法即可 RPC测试，不能很好地debug，因为是RPC请求 自己构造client测试，需要另外写代码构造client 通过postman测试, 本地需要启动服务，或者通过json-rpc协议使用postman测试alpha环境 从IDE启动服务按照fin.settle_job_build.yml定义的顺序部署好文件后。 配置[Run/Debug Configurations]: 设置[Application] fin.settle_job的: Main class: me.ele.fin.job.MainApplication Working directory: /Users/joshua/finance/settle/settle-job/settle-job-service/deploy。定位到deploy目录下，因为经过ci_success.sh后，所有的conf和lib都位于此目录下 Use classpath of module: settle-job-service 直接启动，启动过程中观察对应的日志 启动后可以使用postman发送请求,在IDE中设置断点，直接进行Debug POSTMAN使用方法如下methodpost: http://vpca-fin-settle-query-1.vm.elenet.me:8092/rpc body123456789&#123; &quot;ver&quot;: &quot;1.0&quot;, &quot;soa&quot;: &#123;&quot;req&quot;:&quot;12345&quot;,&quot;rpc&quot;:&quot;clientAppId|1.4.5.2&quot;&#125;, &quot;context&quot;: &#123;&quot;type&quot;:&quot;lpt&quot;&#125;, &quot;iface&quot;: &quot;me.ele.fin.settlement.api.soa.ISettlementSampleApi&quot;, &quot;method&quot;: &quot;helloWorld&quot;, &quot;args&quot;: &#123;&quot;form&quot;:&quot;&#123;\&quot;name\&quot;:\&quot;test\&quot;&#125;&quot;&#125;, &quot;metas&quot;: &#123;&#125;&#125; response12345678&#123; &quot;ver&quot;: &quot;1.0&quot;, &quot;soa&quot;: &#123; &quot;req&quot;: &quot;12345&quot; &#125;, &quot;result&quot;: &quot;&#123;\&quot;message\&quot;:\&quot;hello world test\&quot;&#125;&quot;, &quot;ex&quot;: null&#125; 也可以在本地启动服务，进行测试，参考App_id_build.yml中的步骤: 123456cd settlemvn clean package -U -f settle-settlement/pom.xml -DskipTests=truechmod +x settle-settlement/settle-settlement-service/deploy/ci_success.shsettle-settlement/settle-settlement-service/deploy/ci_success.shcd settle/settle-settlement/settle-settlement-service/deploysh start.sh post: http://localhost:8092/rpc body 123456789&#123; &quot;ver&quot;: &quot;1.0&quot;, &quot;soa&quot;: &#123;&quot;req&quot;:&quot;12345&quot;,&quot;rpc&quot;:&quot;clientAppId|1.4.5.2&quot;&#125;, &quot;context&quot;: &#123;&quot;type&quot;:&quot;lpt&quot;&#125;, &quot;iface&quot;: &quot;me.ele.fin.settlement.api.soa.ISettlementService&quot;, &quot;method&quot;: &quot;processBizSettle&quot;, &quot;args&quot;: &#123;&quot;form&quot;:&quot;&#123;\&quot;restaurantId\&quot;:123, \&quot;OrderId\&quot;: 123, \&quot;transNo\&quot;: \&quot;2016\&quot;, \&quot;businessType\&quot;: 1, \&quot;operateType\&quot;:1, \&quot;comment\&quot;: \&quot;hello\&quot;, \&quot;amount\&quot;: 1.23, \&quot;compensationRate\&quot;: 1.23&#125;&quot;&#125;, &quot;metas&quot;: &#123;&#125;&#125; response: 12345678&#123; &quot;ver&quot;: &quot;1.0&quot;, &quot;soa&quot;: &#123; &quot;req&quot;: &quot;12345&quot; &#125;, &quot;result&quot;: &quot;null&quot;, &quot;ex&quot;: null&#125; SOA调用因为pylon初始化时已经initClients了，所以直接构造client即可: 12TimeLineSearchService timeLineSearchService = (TimeLineSearchService) ClientUtil.getContext().getClients(TimeLineSearchService.class); 直接调用对应接口即可。 发布相关发布最主要的脚本为位于根目录下的$appid_build.yml文件 具体过程参考$appid_build.yml文件说明 可以在本地运行文件中相关命令以验证 以fin.settle_clearing_build.yml为例: mvn clean package -U -f pom.xml -DskipTests=true 构建所有jar包，并跳过测试(使用settle/pom.xml) build节点意义如下: 1. `maven-compiler-plugin`: 生成java包 2. `maven-source-plugin`: 生成sources源码包 此时会生成module下定义的所有包 123456789&lt;modules&gt; &lt;module&gt;bill-query&lt;/module&gt; &lt;module&gt;settle-clearing&lt;/module&gt; &lt;module&gt;settle-dataretry&lt;/module&gt; &lt;module&gt;settle-datasync&lt;/module&gt; &lt;module&gt;settle-job&lt;/module&gt; &lt;module&gt;settle-query&lt;/module&gt; &lt;module&gt;settle-settlement&lt;/module&gt;&lt;/modules&gt; 生成日志如下: 12345678910[INFO] settle ............................................. SUCCESS [ 0.685 s][INFO] bill-query ......................................... SUCCESS [ 2.565 s][INFO] settle-clearing .................................... SUCCESS [ 0.009 s][INFO] settle-clearing-api ................................ SUCCESS [ 0.342 s][INFO] settle-clearing-service ............................ SUCCESS [ 2.688 s][INFO] settle-dataretry ................................... SUCCESS [ 0.151 s][INFO] settle-datasync .................................... SUCCESS [ 0.144 s][INFO] settle-job ......................................... SUCCESS [ 0.141 s][INFO] settle-query ....................................... SUCCESS [ 0.173 s][INFO] settle-settlement .................................. SUCCESS [ 0.158 s] 对应的目录如下: 12345678910111213141516171819202122232425262728293031323334353637383940.├── README.md├── bill-query│ ├── bill-query.iml│ ├── pom.xml│ ├── src│ └── target├── fin.settle_clearing_build.yml├── pom.xml├── settle-clearing│ ├── pom.xml│ ├── settle-clearing-api│ ├── settle-clearing-service│ └── settle-clearing.iml├── settle-dataretry│ ├── pom.xml│ ├── settle-dataretry.iml│ ├── src│ └── target├── settle-datasync│ ├── pom.xml│ ├── settle-datasync.iml│ ├── src│ └── target├── settle-job│ ├── pom.xml│ ├── settle-job.iml│ ├── src│ └── target├── settle-query│ ├── pom.xml│ ├── settle-query.iml│ ├── src│ └── target├── settle-settlement│ ├── pom.xml│ ├── settle-settlement.iml│ ├── src│ └── target└── settle.iml 注意settle-clearing划分为了settle-clearing-api,settle-clearing-service两个Module 对应的jar包如下: 12345678910111213141516.//bill-query/target/bill-query-1.0-SNAPSHOT-sources.jar.//bill-query/target/bill-query-1.0-SNAPSHOT.jar.//settle-clearing/settle-clearing-api/target/settle-clearing-api-1.0-SNAPSHOT-sources.jar.//settle-clearing/settle-clearing-api/target/settle-clearing-api-1.0-SNAPSHOT.jar.//settle-clearing/settle-clearing-service/target/settle-clearing-service-1.0-SNAPSHOT-sources.jar.//settle-clearing/settle-clearing-service/target/settle-clearing-service-1.0-SNAPSHOT.jar.//settle-dataretry/target/settle-dataretry-1.0-SNAPSHOT-sources.jar.//settle-dataretry/target/settle-dataretry-1.0-SNAPSHOT.jar.//settle-datasync/target/settle-datasync-1.0-SNAPSHOT-sources.jar.//settle-datasync/target/settle-datasync-1.0-SNAPSHOT.jar.//settle-job/target/settle-job-1.0-SNAPSHOT-sources.jar.//settle-job/target/settle-job-1.0-SNAPSHOT.jar.//settle-query/target/settle-query-1.0-SNAPSHOT-sources.jar.//settle-query/target/settle-query-1.0-SNAPSHOT.jar.//settle-settlement/target/settle-settlement-1.0-SNAPSHOT-sources.jar.//settle-settlement/target/settle-settlement-1.0-SNAPSHOT.jar after_success 123after_success: - chmod +x settle-clearing/settle-clearing-service/deploy/ci_success.sh - settle-clearing/settle-clearing-service/deploy/ci_success.sh 运行ci_success.sh，将settle-clearing/settle-clearing-service下面的zip文件(settle-clearing-service.zip)放在deploy目录下 settle-clearing-service.zip的生成依赖于settle-clearing/settle-clearing-service/pom.xml的定义， 其中的build节点定义了编译打包配置 settle-clearing-service.zip结构为 123456789101112lib/ ... pylon-rpc-2.0.16.jar pylon-spring-2.0.16.jar settle-clearing-api-1.0-SNAPSHOT.jar settle-clearing-service-1.0-SNAPSHOT.jar sigar-1.6.4.jar slf4j-api-1.7.6.jar ...``` 此时所有的待发布文件存储在deploy目录下，对应的结构为 deploy/ lib/ .jar conf/ .json *.properties12345所有的配置文件也可以放在deploy目录下，使用基于classpath的目录获取文件路径`&quot;classpath:/application.properties&quot;`也可以使用基于根目录(deploy)的方式获取路径(/conf),因为此时根目录即为deploy- 最终部署 outfile: settle-clearing/settle-clearing-service/deploy 12345678910111213141516171819发布系统将`deploy`下的所有目录抽取部署至`/data/appid`,并运行`start.sh`启动服务其中`CLASS_PATH=&quot;$PROJECT_DIR/conf:$PROJECT_DIR/lib/*:$CLASS_PATH&quot;`将`conf`,`lib`目录放入classpath中## Pylon相关### 原理pylon原理: 提供对应的接口(interface)定义给pylon，服务方实现对应的接口。有对应的请求时，pylon会生成代理对象，调用service对这个接口的具体实现。### 接口定义 参照`transaction_scoring_system` 由`Configure.json`中的`serverConf`提供对应SOA服务的接口定义 “serverConf”: {“name”: “pts.score”,“protocol”: “json”,“group”: “local”,“port”: 8088,“threadPoolSize”: 24,“bufferQueueSize”: 30,“initializer”: “me.ele.pts.score.impl.soa.TransactionScoringServiceInitializer”,“interfaces”: [ “me.ele.pts.score.service.IRestaurantTransactionScore”, “me.ele.pts.score.service.IUserTransactionScore”]},``` 其中的interfaces定义好了对外提供的接口，同时注册在huskar的service中 此处接口定义在me.ele.pts.api.OrderApiService中 Bean注入ServiceInitializer.init()初始化资源。 appContext = new AnnotationConfigApplicationContext(MainApplication.class);会将MainApplication.class作为配置文件注入所有bean（因为MainApplication使用了@Configuration注解） 同时因为在MainApplication中定义了bean组件扫描的package: @ComponentScan(basePackages = &quot;me.ele.fin.settlement.impl&quot;),所以定义在me.ele.fin.settlement.impl下所有的bean会在初始化时注入IOC容器。 脚本 crontab sh对应的java程序main函数（不推荐） ScheduledThreadPoolExecutor jobplus 参考 Pylon 2.0接入文档或者参考pdf版本 其他 打包: 使用maven-assembly-plugin插件，配合dist.xml，conf目录存放配置文件，bin目录存放可执行脚本，lib目录存放所有依赖jar包。 profile: 环境参数相关（和开发无关，略） 多module/多package的结构都可以]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[我的vim]]></title>
      <url>%2F2016%2F12%2F15%2Fmy_vim%2F</url>
      <content type="text"><![CDATA[关于vim常言道: 工欲善其事，必先利其器。作为一个程序员，一个常用的工具就是编辑器。相比IDE，vim具有以下几种特性: 跨平台及统一环境 无论是在windows还是在*nix，vim是一个很完美的跨平台文本编辑器。 定制化及可扩展 vim提供一个vimrc的配置文件来配置vim，并且自己可以定制一些插件来实现各种功能 高效命令行 使用vim编辑文本，只需在键盘上操作就可以，根本无需用到鼠标。 笔者最终配置的vim如下图所示: 对应的repo为: https://github.com/joshua-hw/my_vim 配置如果你需要配置vim，只需在Home目录创建一个~/.vimrc文件即可以配置vim了。以下是笔者的.vimrc文件内容。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394&quot;自己定义vimrc常见设置和一些键位的设置&quot;---------------- 加载插件管理文件 --------------------if filereadable(expand(&quot;~/.vimrc.bundles&quot;)) source ~/.vimrc.bundlesendif&quot; 在插入模式下MAC下的delete不能删除问题set backspace=2set colorcolumn=80&quot;--------------- leader设定 -------------let mapleader = &apos;,&apos;let g:mapleader = &apos;,&apos;&quot;------------------------------- 基本设置 -----------------------------------&quot;开启语法高亮&quot;syntax enable 该命令只在当前文件有效syntax on &quot; 所有缓冲区文件都有效&quot;-------------- 文件检测 ----------------------filetype onfiletype indent onfiletype plugin onfiletype plugin indent oncolorscheme blackbeauty &quot; 配色主题set autoread &quot; 文件修改之后自动载入。set shortmess=atI &quot; 启动的时候不显示那个援助索马里儿童的提示set laststatus=2&quot;set confirm &quot; 取消光标闪烁set noswapfile &quot; 关闭交换文件set wildignore=*.swp,*.bak,*.pyc,*.class,.svnset cursorcolumn &quot; 突出显示当前列set cursorline &quot; 突出显示当前行set title set novisualbellset noerrorbellsset magicset ruler &quot; 显示当前行号和列号set number &quot; 显示行号set nowrap &quot; 取消换行set showcmd &quot; 在状态栏显示正在输入的命令set showmode &quot; 显示vim模式set showmatch &quot; 括号匹配，高亮set matchtime=1 set hlsearch &quot; 高亮搜索的文本set incsearch &quot; 即时搜索set ignorecase &quot; 搜索忽略大小写set smartcase &quot; 有一个或以上大写字母时仍大小敏感set foldenable &quot; 代码折叠set foldmethod=indentset foldlevel=99 &quot; autosave&quot;let g:auto_save = 1 &quot; enable AutoSave on Vim startup&quot;let g:auto_save_no_updatetime = 1 &quot; do not change the &apos;updatetime&apos; option&quot;let g:auto_save_in_insert_mode = 0 &quot; do not save while in insert mode&quot;let g:auto_save_silent = 1 &quot; do not display the auto-save notification&quot;let g:auto_save_events = [&quot;InsertLeave&quot;, &quot;TextChanged&quot;]&quot;let g:auto_save_keep_marks = 0&quot; 代码折叠自定义快捷键let g:FoldMethod = 0map &lt;leader&gt;zz :call ToggleFold()&lt;cr&gt;fun! ToggleFold() if g:FoldMethod == 0 exe &quot;normal! zM&quot; let g:FoldMethod = 1 else exe &quot;normal! zR&quot; let g:FoldMethod = 0 endifendfunset smartindent &quot; 智能缩进set autoindent &quot; 自动缩进&quot;------------------------------- tab 相关设置 ---------------------set tabstop=4 &quot; 设置tab的宽度set shiftwidth=4 &quot; 每一次缩进对应的空格数set softtabstop=4 &quot; 按退格键是可以一次删除4个空格set smarttab set expandtab &quot; 将tab自动转化为空格set shiftround &quot; 缩进时，取整&quot;------------------------------- 文件编码 -------------------------set encoding=utf-8set fileencodings=utf-8,ucs-bom,shift-jis,gb18030,gbkgb2312,cp936 &quot; 自动判断编码set helplang=cnset ffs=unix,mac,dosset formatoptions+=B &quot; 合并两行中文时，不在中间加空格set termencoding=utf-8 &quot; 终端编码&quot;------------------------------- 其他设置 -------------------------set completeopt=longest,menu &quot; 让vim的补全菜单和ide一致set wildmenuset wildignore=*.0,*~,*.pyc,*.classautocmd! bufwritepost .vimrc source % &quot; vimrc 文件修改后自动加载&quot;------------------------------- 自定义快捷键设置 -----------------&quot; 关闭方向键，使用hjklmap &lt;Left&gt; &lt;Nop&gt; map &lt;Right&gt; &lt;Nop&gt;map &lt;Up&gt; &lt;Nop&gt;map &lt;Down&gt; &lt;Nop&gt; &quot; 行首 和 行尾 mapnoremap H ^noremap L $&quot; 切换到命令模式map noremap ; :&quot; 插入模式下 kj 映射到 Escinoremap kj &lt;Esc&gt; nnoremap &lt;leader&gt;q :q!&lt;CR&gt;nnoremap &lt;leader&gt;w :wq&lt;CR&gt;&quot; 分屏切换noremap w&lt;up&gt; &lt;c-w&gt;&lt;up&gt;noremap wk &lt;c-w&gt;&lt;up&gt;noremap w&lt;left&gt; &lt;c-w&gt;&lt;left&gt;noremap wh &lt;c-w&gt;&lt;left&gt;noremap w&lt;right&gt; &lt;c-w&gt;&lt;right&gt;noremap wl &lt;c-w&gt;&lt;right&gt;noremap w&lt;down&gt; &lt;c-w&gt;&lt;down&gt;noremap wj &lt;c-w&gt;&lt;down&gt;&quot; python 文件的一般设置autocmd FileType python set tabstop=4 shiftwidth=4 expandtab ai&quot; php自动完成autocmd FileType php set omnifunc=phpcomplete#CompletePHP&quot; 当文件类型为php时，将系统自动补全的快捷键更改为 ,aautocmd FileType php inoremap &lt;leader&gt;a &lt;C-x&gt;&lt;C-o&gt;&quot; 只有在是PHP文件时，才启用PHP补全au FileType php call AddPHPFuncList()function! AddPHPFuncList() set dictionary-=~/.vim/funclist.txt dictionary+=~/.vim/funclist.txt set complete-=k complete+=kendfunction&quot; phpqalet g:phpqa_php_cmd=&apos;php&apos;let g:phpqa_codesniffer_args = &quot;--standard=PSR2&quot; &quot; Set the codesniffer argslet g:phpqa_codesniffer_cmd=&apos;phpcs&apos; &quot; PHP Code Sniffer binary (default = \&quot;phpcs\&quot;)let g:phpqa_messdetector_cmd=&apos;phpmd&apos; &quot; PHP Mess Detector binary (default = \&quot;phpmd\&quot;)let g:phpqa_messdetector_autorun = 0 &quot; Don&apos;t run messdetector on save (default = 1)let g:phpqa_codesniffer_autorun = 0 &quot; Don&apos;t run codesniffer on save (default = 1)let g:phpqa_codecoverage_autorun = 1 &quot; Show code coverage on load (default = 0)&quot; Clover code coverage XML file&quot; let g:phpqa_codecoverage_file = \&quot;/path/to/clover.xml\&quot;&quot; &quot; Show markers for lines that ARE covered by tests (default = 1)let g:phpqa_codecoverage_showcovered = 0 &quot; Stop the location list opening automaticallylet g:phpqa_open_loc = 0&quot; 定义函数AutoSetFileHead，自动插入文件头autocmd BufNewFile *.sh,*.py exec &quot;:call AutoSetFileHead()&quot;function! AutoSetFileHead()&quot;如果文件类型为.sh文件if &amp;filetype == &apos;sh&apos; call setline(1, &quot;\#!/bin/bash&quot;)endif&quot;如果文件类型为pythonif &amp;filetype == &apos;python&apos; call setline(1, &quot;\#!/usr/bin/env python&quot;) call append(1, &quot;\# -*- coding: utf-8 -*- &quot;)endif normal G normal o normal oendfunc&quot;set some keyword to highlightif has(&quot;autocmd&quot;) &quot;Highlight TODO, FIXME, NOTE, etc. if v:version &gt; 701 autocmd Syntax * call matchadd(&apos;Todo&apos;, &apos;\W\zs\(TODO\|FIXME\|CHANGED\|DONE\|XXX\|BUG\|HACK\)&apos;) autocmd Syntax * call matchadd(&apos;Debug&apos;, &apos;\W\zs\(NOTE\|INFO\|IDEA\|NOTICE\)&apos;) endifendif&quot; ----------------------- 插件设置 ------------------------------&quot; *********************** NERDTree 插件设置 *********************&quot; vim启动时触发&quot; autocmd vimenter * NERDTreemap &lt;leader&gt;n :NERDTreeToggle&lt;CR&gt;autocmd bufenter * if (winnr(&quot;$&quot;) == 1 &amp;&amp; exists(&quot;b:NERDTreeType&quot;) &amp;&amp; b:NERDTreeType == &quot;primary&quot;) | q | endiflet NERDTreeShowLineNumbers=1let NERDTreeIgnore=[&apos;\.pyc$&apos;, &apos;\~$&apos;]&quot; 分屏打开文件let g:NERDTreeMapOpenVSplit = &apos;v&apos; let g:NERDTreeMapOpenSplit = &apos;s&apos; &quot; *********************** tagbar 插件设置 ***********************map &lt;leader&gt;g :TagbarToggle&lt;CR&gt;let g:tagbar_auto_focus=1&quot; *********************** taglist 插件设置 **********************let Tlist_Ctags_Cmd=&quot;/usr/local/bin/ctags&quot;let Tlist_Show_One_File=1let Tlist_Exit_OnlyWindow=1let Tlist_Auto_Open=0let Tlist_Auto_Highlight_Tag=1let Tlist_Use_Right_Window=1let Tlist_WinWidth=35&quot; *********************** 快速跳转 ******************************let g:EasyMotion_smartcase=1map &lt;leader&gt;&lt;leader&gt;h &lt;Plug&gt;(easymotion-linebackward)map &lt;leader&gt;&lt;leader&gt;j &lt;Plug&gt;(easymotion-j)map &lt;leader&gt;&lt;leader&gt;k &lt;Plug&gt;(easymotion-k)map &lt;leader&gt;&lt;leader&gt;l &lt;Plug&gt;(easymotion-lineforward)map &lt;leader&gt;&lt;leader&gt;. &lt;Plug&gt;(easymotion-repeat)&quot; *********************** 语法检查 ******************************let g:syntastic_error_symbol=&apos;&gt;&gt;&apos;let g:syntastic_warning_symbol=&apos;&gt;&apos;let g:syntastic_check_on_open=1let g:syntastic_check_on_wq=0let g:syntastic_enable_highlighting=1let g:syntastic_python_checkers=[&apos;pyflakes&apos;, &apos;pep8&apos;]let g:syntastic_python_pep8_args=&apos;--ignore=E501,E225&apos;let g:syntastic_always_populate_loc_list=0let g:syntastic_auto_loc_list=0let g:syntastic_loc_list_height=3function! ToggleErrors() let old_last_winnr = winnr(&apos;$&apos;) lclose if old_last_winnr == winnr(&apos;$&apos;) &quot;Nothing was closed, open syntastic error location panel Errors endifendfunctionnnoremap &lt;leader&gt;s :call ToggleErrors()&lt;cr&gt;&quot; *********************** autopep8语法检查 ******************************let g:autopep8_max_line_length=79&quot; *********************** 自动补全引号等插件设置 ****************au FileType python let b:delimitMate_nesting_quotes = [&apos;&quot;&apos;]&quot; ********************** 全局搜索 ***********************let g:ag_prg = &quot;ag --nogroup --nocolor --column&quot;&quot; python 相关语法检查let g:pyflakes_use_quickfix = 0let python_highlight_all = 1&quot; *********************** markdown 插件设置 *********************let g:vim_markdown_folding_disable = 1&quot; 多光标选中编辑设置&quot; let g:multi_cursor_use_default_mapping = 0&quot; let g:multi_cursor_next_key=&apos;&lt;C-m&gt;&apos;&quot; let g:multi_cursor_prev_key=&apos;&lt;C-p&gt;&apos;&quot; let g:multi_cursor_skip_key=&apos;&lt;C-x&gt;&apos;&quot; let g:multi_cursor_quit_key=&apos;&lt;Esc&gt;&apos;&quot; *********************** 快速注释 ******************************let g:NERDSpaceDelims = 1&quot; *********************** 文件搜索插件 **************************let g:ctrlp_map = &apos;&lt;leader&gt;p&apos;let g:ctrlp_cmd = &apos;CtrlP&apos;map &lt;leader&gt;f : CtrlPMRU&lt;CR&gt;let g:ctrlp_custom_ignore = &#123; \ &apos;dir&apos;: &apos;\v[\/]\.(git|hg|svn|rvm)$&apos;, \ &apos;file&apos;: &apos;\v\.(exe|so|dll|zip|tar|tar.gz|pyc)$&apos;, \&#125;let g:ctrlp_working_path_mode=0let g:ctrlp_match_window_bottom=1let g:ctrlp_max_height=15let g:ctrlp_match_window_reversed=0let g:ctrlp_mruf_max=500let g:ctrlp_follow_symlinks=1&quot; ctrlp相关插件 函数搜索nnoremap &lt;Leader&gt;fu: CtrlPFunky&lt;Cr&gt;nnoremap &lt;Leader&gt;fU:execute &apos;CtrlpFunky &apos; . expand(&apos;&lt;cword&gt;&apos;)&lt;Cr&gt;let g:ctrlp_funky_syntax_highlight = 1let g:ctrlp_extensions = [&apos;funky&apos;]&quot; *********************** pyflakes_vim 插件设置 *****************let g:pyflakes_user_quickfix=0&quot; *********************** python-syntax *************************let python_highlight_all=1&quot; *********************** vim-markdown **************************let g:vim_mardown_folding_disabled=1&quot; *********************** 自动补全插件 **************************let g:ycm_key_list_select_completion=[&apos;&lt;Down&gt;&apos;]let g:ycm_key_lsit_previous_completion=[&apos;&lt;Up&gt;&apos;]let g:ycm_complete_in_comments = 1 &quot;在注释输入中也能补全let g:ycm_complete_in_strings = 1 &quot;在字符串输入中也能补全let g:ycm_use_ultisnips_completer = 1 &quot;提示UltiSnipslet g:ycm_collect_identifiers_from_comments_and_strings = 1 &quot;注释和字符串中的文字也会被收入补全let g:ycm_collect_identifiers_from_tags_files = 1&quot; ********************** 对齐线设置 ****************************let g:indent_guides_enable_on_vim_startup = 0let g:indent_guides_auto_colors = 0let g:indent_guides_guide_size = 1 set ts=4 sw=4 etlet g:indent_guides_start_level = 2autocmd VimEnter,Colorscheme * :hi IndentGuidesOdd guibg=red ctermbg=3autocmd VimEnter,Colorscheme * :hi IndentGuidesEven guibg=green ctermbg=4hi IndentGuidesOdd guibg=red ctermbg=3hi IndentGuidesEven guibg=green ctermbg=4&quot; 跳转到定义处, 分屏打开let g:ycm_goto_buffer_command = &apos;vertical-split&apos;nnoremap &lt;leader&gt;jd :YcmCompleter GoToDefinitionElseDeclaration&lt;CR&gt;nnoremap &lt;leader&gt;gd :YcmCompleter GoToDeclaration&lt;CR&gt;&quot; 引入，可以补全系统，以及python的第三方包 针对新老版本YCM做了兼容&quot; old versionif !empty(glob(&quot;~/.vim/bundle/YouCompleteMe/cpp/ycm/.ycm_extra_conf.py&quot;)) let g:ycm_global_ycm_extra_conf =&quot;~/.vim/bundle/YouCompleteMe/cpp/ycm/.ycm_extra_conf.py&quot;endif&quot; new versionif !empty(glob(&quot;~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/ycm/.ycm_extra_conf.py&quot;)) let g:ycm_global_ycm_extra_conf = &quot;~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/ycm/.ycm_extra_conf.py&quot;endif&quot; 直接触发自动补全 insert模式下&quot; let g:ycm_key_invoke_completion = &apos;&lt;C-Space&gt;&apos;let g:ycm_key_list_select_completion=[&apos;&lt;tab&gt;&apos;, &apos;&lt;Down&gt;&apos;]&quot; 黑名单,不启用let g:ycm_filetype_blacklist = &#123; \ &apos;tagbar&apos; : 1, \ &apos;gitcommit&apos; : 1, \&#125;&quot; last_edit_marker.vim设置nmap &lt;C-y&gt; g&apos;Zaugroup LastEditMarker autocmd! autocmd InsertLeave * normal mZaugroup END&quot; vim，主机复制共享vmap &lt;C-c&gt; &quot;+yvmap &lt;C-x&gt; &quot;+c vmap &lt;C-v&gt; c&lt;ESC&gt;&quot;+p imap &lt;C-v&gt; &lt;C-r&gt;&lt;C-o&gt;+ nmap &lt;C-v&gt; &quot;+p&quot; powerline设置set guifont=PowerlineSymbols\ for\ Powerlineset nocompatibleset laststatus=2set t_Co=256let g:Powerline_symbols = &apos;fancy&apos;let Powerline_symbols=&apos;compatible&apos; &quot; gitgutter设置let g:gitgutter_map_keys = 0let g:gitgutter_enabled = 0let g:gitgutter_highlight_lines = 1nnoremap &lt;leader&gt;gs :GitGutterToggle&lt;CR&gt; 插件使用vumdle管理vim的插件，使用过程如下: 在Home目录创建~/.vim目录和.vimrc文件，可使用上面的.vimrc文件 安装vundle 1git clone https://github.com/gmarik/vundle.git ~/.vim/bundle/vundle 添加一个~/.vimrc.bundles文件来保存所有插件的配置，在~/.vimrc文件加入以下代码片段 123if filereadable(expand(&quot;~/.vimrc.bundles&quot;))source ~/.vimrc.bundlesendif 以下是笔者的.vimrc.bundles文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273set nocompatiblefiletype offset rtp+=~/.vim/bundle/Vundle.vimcall vundle#begin()&quot;------------- 插件列表 ---------------------------&quot;插件设置和vim基本设置单独放置Plugin &apos;gmarik/Vundle.vim&apos;Plugin &apos;itchyny/lightline.vim&apos;Plugin &apos;scrooloose/nerdtree&apos;Plugin &apos;ctrlpvim/ctrlp.vim&apos;Plugin &apos;tacahiroy/ctrlp-funky&apos;Plugin &apos;majutsushi/tagbar&apos;Plugin &apos;taglist.vim&apos;Plugin &apos;basepi/vim-conque&apos;Plugin &apos;Valloric/YouCompleteMe&apos;Plugin &apos;Raimondi/delimitMate&apos;Plugin &apos;scrooloose/syntastic&apos;Plugin &apos;jiangmiao/auto-pairs&apos;Plugin &apos;tpope/vim-commentary&apos;Plugin &apos;sjl/gundo.vim&apos;Plugin &apos;Lokaltog/vim-easymotion&apos;Plugin &apos;tpope/vim-fugitive&apos;&quot; pythonPlugin &apos;kevinw/pyflakes-vim&apos;Plugin &apos;hdima/python-syntax&apos;Plugin &apos;pep8&apos;Plugin &apos;tell-k/vim-autopep8&apos;Plugin &apos;python.vim--Vasiliev&apos;Plugin &apos;hynek/vim-python-pep8-indent&apos;&quot; phpPlugin &apos;shawncplus/phpcomplete.vim&apos;Plugin &apos;joonty/vim-phpqa&apos;&quot; golangPlugin &apos;fatih/vim-go&apos;Plugin &apos;dgryski/vim-godef&apos;Plugin &apos;nsf/gocode&apos;, &#123;&apos;rtp&apos;: &apos;vim/&apos;&#125;&quot; markdownPlugin &apos;plasticboy/vim-markdown&apos;&quot; 多光标Plugin &apos;terryma/vim-multiple-cursors&apos;&quot; 快速注释Plugin &apos;scrooloose/nerdcommenter&apos;&quot; 对齐线Plugin &apos;nathanaelkane/vim-indent-guides&apos;&quot; 全局搜索Plugin &apos;rking/ag.vim&apos;&quot; 跳转到上次修改的地方Plugin &apos;vim-scripts/last_edit_marker.vim&apos;&quot; powerlinePlugin &apos;powerline/powerline&apos;&quot; gitgutterPlugin &apos;airblade/vim-gitgutter&apos;&quot; gitvPlugin &apos;vim-scripts/gitv&apos;call vundle#end()filetype plugin indent on 打开vim，运行:PluginInstall或在shell中直接运行vim +PluginInstall +qall即可安装插件 快捷键笔者设置的vim快捷键如下: key 作用 ,g tagbar ,n nerdtree w[hjkl] 分屏切换 gt 切换tab (文件名上面)(v/Enter) 在(新的/当前)分屏中打开文件 ,q 关闭对应分屏，退出不保存 ,w 关闭并保存 kj insert to normal ,cc 注释 ,cu 取消注释 :vs 纵向切屏 :sp 横向切屏 ,s 语法错误信息 ;/SHIFT+; nornal切换到命令行模式 H/SHIFT+右箭头 行首 L/SHIFT+左箭头 行尾 ,p 打开文件搜索栏 ,jd 跳转到变量定义处 F8 按PEP8标准格式化文件 :Ag create_order –python 全局搜索”create_order” ‘. 移动光标到上一次的修改行 `. 移动光标到上一次的修改点 `` last jump CTRL+O go back CTRL+I go forwards control+y/g’Z 可跨文件跳转到上次修改位置(last_edit_maker提供功能) :new/e/vs/sp/tabe filename 新建/当前tab/纵向/横向/新tab 打开 filename CTRL+c &amp; COMMAND+v vim复制，主机粘贴 COMMAND+c &amp; CTRL+v 主机复制，vim粘贴 ,a insert模式下php文件autocomplete，由phpcomplete的 inoremap而来 ,gs 显示文件的git更改,类似于git diff命令的显示效果 :Gitv 显示项目版本库的更改，类似于tig的效果 :Gblame 在git项目中查看每行最后的更改情况 :Phpcs run code sniffer(代码规范检查, 要求太严格，推荐不用) :Phpmd run mess detector (will ask for a rule XML file if not set，推荐不用)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[服务发布经验]]></title>
      <url>%2F2016%2F12%2F01%2Fabout_deploy%2F</url>
      <content type="text"><![CDATA[发布前发布前的checklist需要包括以下内容 基础服务依赖 应用服务器资源，基础服务资源(db/redis/rmq)需要提前申请。首次上线需要提前联系运维初始化机器 MySql: 需要提前建库，建表，变更字段等 Redis: 需要提前计算容量并确认 rmq: 需要提前申请账号，确认exchange，queue等是否建立，是否需要提前bind SOA服务和接口依赖 依赖服务的集群配置。需要估算请求依赖服务的QPS，和依赖服务owner确认调用集群，确认对方服务是否已经上线 需要提前发发布计划通知调用方和被调用方 上线服务本身配置 服务配置中心上对应的配置是否已经设置 对应的业务开关/灰度开关是否在正确位置 发布系统中对应的配置是否正确 集成测试/回归测试是否正确无误 其他 至少需要一台生产环境机器登陆权限。有可能需要登陆服务器检查服务是否完全正常运行以及不正常运行的原因(日志收集服务有可能不太稳定，可能需要在生产环境进行一些操作和查询，虽然这样不太合理) 发布中基本原则: 所有的发布异常先恢复正常再修复发布问题 发布中需要确认以下事情: 发布时间一般都是避开高峰期。紧急情况在高峰期发布是否可行 发布是否有先后顺序（服务依赖，接口依赖等） 发布时需要通知NOC，方便NOC进行监控和汇集，以便出现问题时知道大概这个时间点有哪些发布 发布时的灰度很重要 每个group至少应该有一台机器独立出来作为灰度机器，每次发布先发这台机器并观察 较大改动前先提前发灰度机器并观察一段时间 发布的合理步长(每次发布一个group里面的多少台机器)为一个group的1/8-1/4，保证发布平滑 发布时需要监控如下内容: 对业务主流程是否有影响 对其他服务是否有影响 和本次发布相关的一些技术指标，业务指标等 有异常第一时间回滚或者关闭功能开关，再查找原因(important)。 发布后 需要校验相关功能已经正确执行 回复对应发布邮件通知各相关方已经正确发布]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[幂等的实现]]></title>
      <url>%2F2016%2F11%2F28%2Fidempotency%2F</url>
      <content type="text"><![CDATA[关于幂等幂等（idempotency）是一个数学与计算机学概念，常见于抽象代数中。在编程中，一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。幂等函数，或幂等方法，是指可以使用相同参数重复执行，并能获得相同结果的函数。这些函数不会影响系统状态，也不用担心重复执行会对系统造成改变。 解决方案1. 查询操作查询一次和查询多次，在数据不变的情况下，查询结果是一样的。在隔离级别为可重复读时，select是天然的幂等操作 2. 删除操作删除操作也是幂等的，删除一次和多次删除结果相同，都是把数据删除。(注意可能返回结果不一样，删除的数据不存在，返回0；删除的数据多条，返回结果多个) 3. 唯一索引，防止新增脏数据唯一索引或唯一组合索引来防止新增数据存在脏数据，不过对DB性能有影响 4. token机制，防止页面重复提交处理流程： 数据提交前要向服务的申请token，token放到redis或jvm内存，token设置有效时间 提交后后台校验token，同时删除token，生成新的token返回 token特点： 要申请，一次有效性，可以限流 注意：redis要用删除操作来判断token，删除成功代表token校验通过，如果用select+delete来校验token，存在并发问题，不建议使用 5. 悲观锁获取数据的时候加锁获取 1select * from table_xxx where id=&apos;xxx&apos; for update; 注意：id字段一定是主键或者唯一索引，不然是锁表，会死人的 悲观锁使用时一般伴随事务一起使用，数据锁定时间可能会很长，根据实际情况选用 6. 乐观锁乐观锁只是在更新数据那一刻锁表，其他时间不锁表，所以相对于悲观锁，效率更高。 乐观锁的实现方式多种多样可以通过version或者其他状态条件： 通过版本号实现 1update table_xxx set name=#name#,version=version+1 where version=#version# 通过条件限制 1update table_xxx set avai_amount=avai_amount-#subAmount# where avai_amount-#subAmount# &gt;= 0 要求：quality-#subQuality# &gt;= ，这个情景适合不用版本号，只更新是做数据安全校验，适合库存模型，扣份额和回滚份额，性能更高 注意：乐观锁的更新操作，最好用主键或者唯一索引来更新,这样是行锁，否则更新时会锁表，上面两个sql改成下面的两个更好 12update table_xxx set name=#name#,version=version+1 where id=#id# and version=#version# update table_xxx set avai_amount=avai_amount-#subAmount# where id=#id# and avai_amount-#subAmount# &gt;= 0 7. 分布式锁还是拿插入数据的例子，如果是分布式系统，构建全局唯一索引比较困难，例如唯一性的字段没法确定，这时候可以引入分布式锁，通过第三方的系统(redis或zookeeper)，在业务系统插入数据或者更新数据，获取分布式锁，然后做操作，之后释放锁，这样其实是把多线程并发的锁的思路，引入多多个系统，也就是分布式系统中的解决思路。 要点：某个长流程处理过程要求不能并发执行，可以在流程执行之前根据某个标志(用户ID+后缀等)获取分布式锁，其他流程执行时获取锁就会失败，也就是同一时间该流程只能有一个能执行成功，执行完成后，释放分布式锁(分布式锁要第三方系统提供) 8. select + insert并发不高的后台系统，或者一些任务JOB，为了支持幂等，支持重复执行，简单的处理方法是，先查询下一些关键数据，判断是否已经执行过，在进行业务处理，就可以了 注意：核心高并发流程不要用这种方法 9. 状态机幂等在设计单据相关的业务，或者是任务相关的业务，肯定会涉及到状态机(状态变更图)，就是业务单据上面有个状态，状态在不同的情况下会发生变更，一般情况下存在有限状态机，这时候，如果状态机已经处于下一个状态，这时候来了一个上一个状态的变更，理论上是不能够变更的，这样的话，保证了有限状态机的幂等。 注意：订单等单据类业务，存在很长的状态流转，一定要深刻理解状态机，对业务系统设计能力提高有很大帮助 10. 对外提供接口的api如何保证幂等如银联提供的付款接口：需要接入商户提交付款请求时附带：source来源，seq序列号source+seq在数据库里面做唯一索引，防止多次付款，(并发时，只能处理一个请求) 重点：对外提供接口为了支持幂等调用，接口有两个字段必须传，一个是来源source，一个是来源方序列号seq，这个两个字段在提供方系统里面做联合唯一索引，这样当第三方调用时，先在本方系统里面查询一下，是否已经处理过，返回相应处理结果；没有处理过，进行相应处理，返回结果。注意，为了幂等友好，一定要先查询一下，是否处理过该笔业务，不查询直接插入业务系统，会报错，但实际已经处理了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[运维之下]]></title>
      <url>%2F2016%2F11%2F21%2Fops%2F</url>
      <content type="text"><![CDATA[《运维之下》——第一章：互联网运维工作 《运维之下》——第二章：运维的烦恼 《运维之下》——第三章：运维平台 《运维之下》——第四章：服务器资源使用率 《运维之下》——第五章：运维的未来 《运维之下》——第六章：系统运维概述 《运维之下》——第七章：资产管理 《运维之下》——第八章：服务器硬件测试选型 《运维之下》——第九章：网络成长之路 《运维之下》——第十章：传输网建设]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[技术人员招聘指南]]></title>
      <url>%2F2016%2F11%2F14%2Finterview%2F</url>
      <content type="text"><![CDATA[本文主要为平台交易支撑研发部技术人员的招聘提供一些建议及指南，主要包括面试的流程，内容及面试评定准则。 一些原则 找出应聘者闪亮的地方 技术上的亮点等 如何获得知识 比 知道什么 重要 学习能力很重要 基础知识 比 操作技能 更重要 扎实的理论比经验性的东西更重要，九层之台，起于累土 从一个简单的问题开始，从广度和深度上不断地跟进这个问题 需要知道应聘者的能力边界在哪里 思路和方法 比 答案 更重要 简历筛选需要从简历的内容上判断应聘者的技术技能,项目经历，工作经历是否和部门的需求相符。 具有以下特点的人可能会比较符合我们的要求: 有大型/一线互联网公司工作经验的人 有电商/O2O公司工作经验的人 技术栈和我们比较匹配，或者能弥补部门技术短板的人 电话面试对于简历比较符合我们需求，但是没有条件进行当面面试的人，可以考虑先进行一轮电话面试。电话面试的主要目的在于对应聘者有一个综合的了解，而不应扣细节。可以: 对应聘者简历中描述的内容进行一些确认 对应聘者简历中未提及的技术点进行一些询问以加强对应聘者技术能力的了解 对应聘者综合素质进行一些判定 电话面试推荐不要超过两轮，并且需要在电话面试后确认是否需要约应聘者进行当面面试。 面试内容以下是当面面试时的一些内容和一些参考问题，一面和二面可以分别从中抽取一些问题询问。题目后面有标注题目的难度，分别对应P4,P5,P6级别(一些问题需要根据回答的深度区分p5/p6） 基础及理论部分 语言基础(python/java/c) python: 元类的概念及使用(p5) 生成器，迭代器(p4) 环境管理(virtualenv,pip)(p4) GIL产生的原因，对python并发的限制等(p5) 装饰器概念，使用场景，代码编写(p4) monkey patch的使用(p5) 描述Python的垃圾回收机制(p5) 引用计数 标记-清除机制 分代技术 java: collection, reflection, IOC, AOP, GC, classloader，Concurrency, generics, spring 解释IoC和DI(p4),实现(p5) 内存分配: 栈，堆，静态区(p4) 内存分配的原则 堆内存分块(p5) 新生代 老年代 永久代 Vector/ArrayList/LinkedList的区别(p4) SpringBean的加载过程 AOP的实现(p5) GC机制, MinorGC &amp; Full GC区别(p5), java内存泄漏场景(p5) 类加载机制(p5) 反射的使用(p5) Thread Dump(p5) C: 指针，内存管理(p5) 编码能力 Error和Exception的概念，使用姿势(p5) 序列化(p4) wordcount程序 正则表达式相关(p4) JIT概念，优点(p5) 编码解决生产者/消费者问题（p5） 实现阻塞队列(p6) 序列化和反序列化的作用，实现(p5) 死锁代码编写(p5) 并发 pid,ppid,pgid,sessionid含义(p5) Thread的sleep和object的wait方法的区别(java)(p5) 线程安全(同步/锁机制)(p5) ThreadLocal概念(p4)，使用(p5)，实现(p6) 协程(p5) 线程状态及转变(p4),线程池的使用(p5),线程池的设计(p6) 三个线程T1,T2,T3,怎样确保顺序执行(p5) join 守护进/线程的含义，作用(p5)及实现(p6) 守护进程 fork;父进程退出;子进程继续执行，成为init进程的子进程(p6) 进程/线程setDaemon作用，使用场景(p5) 网络 OSI网络模型(p4) 三次握手/四次挥手(p4) http cookie/session(p4) post/get/put/delete(p4) restful(p5) http/https区别(p4) cgi/fastcgi/wsgi/servlet作用，原理，区别(p5) socket编程 tcp echo server(p4),多线程/进程echo server(p5), 多路复用echo server(p6) 进程间通信方式(p5) 管道 信号 消息 共享内存 信号量 socket 数据结构 数组，链表，队列，栈，树，堆，图 输出Fibonacci数列(p4) 队列/栈区别(p4) 如何判断链表是否有环(p5) 链表和数组的区别(存储，查找，删除等)(p4) 哈希冲突的处理方法（线性探测，二次哈希等，哈希算法）(p5) 交叉链表求交点(p5) 广度/深度优先遍历二叉树，前中后序遍历(p4) 操作系统 IO模型 同步/异步，阻塞/非阻塞(p4) select/poll/epoll区别,过程(p5) 进程调度 进程调度算法(先来先服务，短作业优先，最高优先权调度等)(p4) 僵尸进程/孤儿进程概念(p5) 死锁的产生及避免(p5) 程序预处理，编译，汇编，链接过程/内容(p4) 静态链接/动态链接(p4) 内存的分页/分段(p4) shell 使用shell求uv/pv(p4) 查找所有包含’python’的进程并kill(p4) 设计模式 代码实现单例模式 MVC模式 数据库 ACID(p4) 脏读/不可重复读/幻读概念(p4)，场景(p5) undo/redo log概念(p5), 作用原理(P6) 事务(p4) 乐观锁/悲观锁概念，使用(p5)，读/写锁，表/行锁 sql注入(p4) 索引以及索引的实现(p5) 数据库操作的瓶颈及优化(p5) 版本管理 svn/git常用命令(p4) git flow工作流(p4) 算法 各种排序算法描述/编码/时(空)间复杂度 插入，选择，归并，快速，堆，冒泡排序等(p5) 查找算法 二分查找，二叉树查找等(p4) 项目及实践部分 项目经验 担任角色，项目内容，项目难点，项目优化等 对于测试驱动开发的理解 技能广度 框架，中间件(db,cache,mq)，存储(关系型/NoSQL) 消息队列的使用场景 技能深度 源码，bug，坑 性能优化的经验描述 Devops ci, docker 故障定位的经验: 过程及改进措施(p5) 微服务 &amp; 架构 幂等概念(p5)，实现(p6) 无状态含义 RPC框架设计(p6) 服务注册/配置(p5) 监控/trace/报警 监控的设置(p5) trace系统原理(p6) 降级，限流，熔断，补偿，负载均衡，容量评估 微服务架构的分布式事务解决方案(p6) 补偿型（TCC） 异步确保型（可靠消息最终一致） 最大努力通知型 设计 开闭原则，MVP, KISS, Design For Failure，CAP(BASE)，DDD 什么是领域模型，什么是事务脚本？贫血模型/充血模型的区别(p6) 大型网站架构应该考虑的问题(p5) 分层 分割 分布式 集群 缓存 异步 冗余 综合部分主要考查应聘者的反应能力，学习能力，个人态度等 面试评定面试完成后，面试官需要对应聘者给出评价，多个面试官沟通后需要给出结论是否通过，并给出对应的技术评级（参考打怪升级指南）。 参考 我是怎么招聘程序员的 再谈“我是怎么招聘程序员的”（上） 再谈“我是怎么招聘程序员的”（下） 软件人员招聘]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[如何设计一门语言]]></title>
      <url>%2F2016%2F11%2F12%2Fhow_to_design_a_language%2F</url>
      <content type="text"><![CDATA[目录 如何设计一门语言（一）——什么是坑(a) 如何设计一门语言（二）——什么是坑(b) 如何设计一门语言（三）——什么是坑(面向对象和异常处理) 如何设计一门语言（四）——什么是坑(操作模板) 如何设计一门语言（五）——面向对象和消息发送 如何设计一门语言（六）——exception和error code 如何设计一门语言（七）——闭包、lambda和interface 如何设计一门语言（八）——异步编程和CPS变换 如何设计一门语言（九）——类型 如何设计一门语言（十）——正则表达式与领域特定语言（DSL） 如何设计一门语言（十一）——删减语言的功能 如何设计一门语言（十二）——设计可扩展的类型]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[关于灾备]]></title>
      <url>%2F2016%2F11%2F02%2Fdisaster_recovery%2F</url>
      <content type="text"><![CDATA[形式为了保证业务的高可用，需要保证关键业务做好灾备。 网站灾备方案不但承担容灾的任务，很多时候也承担着负载均衡，优化性能的任务。网站灾备有以下几种方式。 主备镜像(冷备)两个数据中心服务器部署完全一样，每次网站发布都要在两个数据中心同时发布，保证运行系统版本一致。两个数据中心有主备之分，数据通过准实时的同步系统从主站不断同步到备站。主站发生灾害性故障导致完全不可用，则将域名解析切换到备站。这种方案纯粹是为了容灾。 业务互补，数据同步如某网站美国机房和国内机房部署的服务在业务上互补，美国机房部署买家服务，国内机房部署卖家服务，海外用户（主要是买家）访问美国机房，国内用户（主要是卖家）访问国内机房。主要业务数据互相实时同步，因为数据在两个机房同时写入，可能会发生冲突。 主主镜像(多活)部署和发布模式与主备一样，但是多个数据中心是同时启用的，根据用户地域将域名解析到不同的机房，数据实时同步。如新浪微博。 如北方用户访问北京机房，南方用户访问上海机房。主要业务数据互相实时同步。 一写多读(类似于DB单master多slave)数据写入只发生在一个数据中心，但是为了加快地区用户访问，会将数据同步到其他数据中心供只读访问。这种方案适用于读多写少的网站。比如wikipedia。 本文讨论主备镜像形式的灾备。 流程(主备镜像)灾备对应的流程如下: 关键点数据灾备灾备的重点在于数据，即灾难发生后可以确保用户原有的数据不会丢失或者遭到破坏。解决方案是依赖基于网络的数据复制工具，实现生产中心和灾备中心之间的异步/同步的数据传输 数据灾备包括DB, rmq, cache的灾备 DB的灾备依赖DB的主从复制实现 由于架构设计时rmq不建议使用在关键链路，并且应该提供对应的业务补偿，所以不考虑同步rmq的数据 关键链路中cache只允许使用作缓存，所以不需要考虑同步数据 应用灾备应用灾备是把应用处理能力再复制一份，也就是在异地灾备中心再构建一套支撑系统。应用灾备能提供应用接管能力，即在生产中心发生故障的情况下，能够在灾备中心接管应用，从而尽量减少系统停机时间，提高业务连续性。 注意点 由于应用灾备可能并未覆盖全路径，所以灾备环境调用未部署服务时需要做容错/降级处理 数据同步的技术多种多样，即可以基于存储阵列的复制软件实现，比如EMC MirrorView、H3C Replication等，也可以基于服务器或者应用软件实现，比如Veritas VVR、Oracle DataGuard等。但不管采用何种技术，都只是在不同的层面实现了数据的同步，要具备应用接管，还需要其他组件的配合，比如DNS域名切换解析、备用网络启用、应用服务切换等等。 cache未做数据同步时，在生产流量切换到灾备时，为了防止灾备所有流量打到DB，可能需要在流量切换前做cache预热 数据表冲突的防止。在做DB切换时，需要防止主键冲突，因此auto_increment的字段需要调整自增因子等 应用服务集群切换可以在服务注册中心处理 切换至冷备机器时，对于有状态的数据，需要在切换前修复数据状态；对于需要事件驱动状态向前的数据，需要复现事件或者手动推动状态向前。总而言之，要保证切换到灾备后，状态机(业务流程)在任何点中断时，系统能够推进状态机走到终态(important) 需要考虑跨机房数据延时问题（以及由此造成的一系列数据问题），需要容忍数据丢失，并为数据延时考虑相应的对策]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[微服务架构的分布式事务解决方案]]></title>
      <url>%2F2016%2F10%2F25%2Fdistributed-transaction-in-soa%2F</url>
      <content type="text"><![CDATA[补偿型 异步确保型 最大努力通知型]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[延时任务]]></title>
      <url>%2F2016%2F10%2F10%2Fdelay_task%2F</url>
      <content type="text"><![CDATA[背景应用中都有延时任务的需求，需要任务在指定的时间之后执行，这里讨论一下延时任务的技术实现。 实现方式实现方式主要有以下几种: rabbitmq + dead letter exchange或者rabbitmq + exchange plugin: x-delayed-message。利用queue的x-message-ttl控制消息延时时间 DB轮询。将task存储在DB中，并设置task的执行时间，同时轮询DB取出当前需要执行的task执行。优点是可结合DB事务，缺点是可能存在单点问题 rabbitmq存储task，consumer延时处理。consumer端sleep N秒。当N较大时，mq中可能会堆积大量消息 使用beanstalkd, nsq等天生很好支持延时特性的queue，但是使用较少，社区缺少相应的技术支持 dead letter exchange此处介绍一下DLX的创建, DLX的整体流程如下: 1delay_exchange =&gt; delay_queue =&gt; biz_exchange =&gt; biz_queue 创建流程如下: 创建延时exchange: delay_exchange 创建延时queue: delay_queue 设置延迟时间: x-message-ttl 设置消息到达expire时间后转到的exchange: x-dead-letter-exchange，需要为真正的业务exchange(biz_exchange) 设置delay_queue和delay_exchange的绑定 创建业务exchange: biz_exchange 创建业务queue: biz_queue 设置biz_exchange和biz_queue的绑定 此时发送到delay_exchange的消息，会在x-message-ttl设置的时间后，经过delay_queue转到biz_exchange，即到biz_queue里面。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[消息补偿]]></title>
      <url>%2F2016%2F09%2F29%2Fmq_back_up%2F</url>
      <content type="text"><![CDATA[Design For FailureDesign For Failure的核心思想在于: 容忍错误，快速恢复，将failure当做普通事件处理。 当应用构建在云服务(cloud)上，这个概念更多被提及(Design For Failure Is Key To Success In The Cloud)。因为相比普通线上环境，云设施的复杂度更大，同时也导致了稳定性以及健壮性的复杂，因此Failure在云环境需要被当做普通事件处理。最佳实践可参考The Netflix Simian Army 同时对于正常环境，Design For Failure的设计思想在保证服务的健壮性，可用性上也大有裨益。 饿了么订单系统在Design For Failure思想上的实践主要有以下四个内容。第一是消息广播补偿，第二是主流程补偿，第三是灾备，第四是随机故障测试系统。 本文详细介绍一下消息广播补偿 补偿方案补偿方案可以考虑: 不同介质的补偿，如mq/redis互相补偿 不同交互方式的补偿，如push/pull结合的补偿 失败操作的Retry补偿 记录操作状态，轮询失败状态补偿 为了保证消息的高可用，将发送的消息同时存储到另外一种介质。出于性能和吞吐量上的考虑，此处考虑选择使用redis。rabbitmq发送消息时，同时保存对应routing_key的订单号到redis对应的zset中，并提供接口在rabbitmq异常时查询一定时间段内对应routing_key的订单号 存储方案由于发送的消息均有一个routing_key(订单状态转变时发送对应routing_key的订单)，所以在存储时应该将消息以routing_key分类存放。考虑将order_id存储在以routing_key为key的zset中，同时以创建时间的时间戳作为zset的score，方便获取指定时间内的订单号 1zadd(routing_key, int(time.time()), order_id) 容量计算由于每个订单的生命周期发出的消息平均约为5条，如订单的峰值TPS为1000，订单号为18位，需要提供查询半个小时之内的消息，根据解决方案可知需要至少存储1小时的内容，则需要的内存为 13600 * 1000 * 18 * 5 / 1024 / 1024 = 309M 查询接口同时需要提供查询接口查询一段时间内对应routing_key的订单号，对应接口定义如下: 123map&lt;string, list&lt;i64&gt;&gt; get_mq_order_ids(1: list&lt;string&gt; routing_keys, 2: Timestamp from_datetime, 3: Timestamp to_datetime)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[全链路性能测试 & 性能分析]]></title>
      <url>%2F2016%2F09%2F21%2Fload-testing-and-performance%2F</url>
      <content type="text"><![CDATA[Best Ref: 性能调优攻略 基本知识性能测试性能测试，是通过自动化的测试工具模拟多种正常、峰值以及异常负载条件来对系统的各项性能指标进行测试。区别于压力测试,在于压力测试要求进行超过规定性能指标的测试。 性能测试的目标为公司交易的主链路，包括外卖平台,商户平台,开放平台,大物流,EOS订单业务,新支付,ERS餐厅业务等。 测试基本过程框架测试团队创建测试用户，测试餐厅，使用测试框架(jmeter)脚本模拟用户下单，餐厅接单，并且对中间支付，物流环节mock。从而对下单到配送的全链路进行性能测试。 性能测试和生产流程的差异如下: 支付mock: 在调用支付的接口时，调用方使用特殊的merchant_id=101。测试团队mock支付调用的第三方服务，返回支付成功或者失败的结果。请求流程为 soa =&gt; payment =&gt; mock service(mock第三方支付服务) 物流特殊处理: 正常情况下，在订单确认之后，只要餐厅购买了配送服务，就会进入物流，不过物流加了一层控制，可以把这些订单过滤掉。目前平台有20k的餐厅，专门用来压测，这些压测订单的物流会忽略 测试接口的调用，调用比率均通过分析对应服务集群的日志来确定。 测试团队相关知识业务部门性能测试 测试准备测试前，noc会进行以下操作: 开店 首页banner，皮肤，自动关店，hermes，base.hermes降级，支付mock开关打开 监控测试过程中需要对业务相关指标进行监控，PTS主要包括以下业务 zeus.eos需要注意以下指标: eos关键调用指标, 主要用于监控主流程相关接口指标 eos相关关键指标，主要用于监控cache，async task,txdaemon执行情况 eos接口总体指标，主要用于对接口总体情况有一个大致的了解 监控需要结合eos主流程来分析问题，EOS主流程如下: 涉密不予提供 同时需要了解EOS状态机各节点的含义和流转逻辑。 osc.bacchus订单催单/取消订单服务，对应监控面板: osc.bacchus 主要关注自动取消订单(hitcount(stats.apps.osc.bacchus.real_cancel_order, &#39;60s&#39;)) 和 自动关店(hitcount(stats.apps.osc.bacchus.real_close_restaurant, &#39;60s&#39;)) 的指标 osc.chronos准时达服务，对应监控面板: osc.chronos 主要的关注目标chronos的队列消息情况，osc.chronos会有最大700k的unack量，其他两个队列是监听blink和eos的消息，可以查看是否有堆积。另外可以关注chronos的机器负载情况，是否有负载过高的情形 osc.blink物流对接服务，对应监控面板: osc.blink 问题分析业务问题分析前提在于要对订单主流程熟悉。由于订单连接了外卖平台,商户平台,大物流,支付，所以当主流程(包括EOS和其他方)出现问题时，一般会反映在订单实际状态扭转上，可以据此并结合EOS自身的关键流程接口相关指标确认出问题的业务方。 技术问题分析可以借助用来分析的工具包括grafana,etrace,elk，特殊情况也可以直接登陆服务器通过log,分析工具htop,perf,tcpdump等进行分析 进行性能分析前，需要了解EOS的架构: eos架构 基础服务指标监控如下: corvus &amp; redis redis监控地址: system-monitor-redis-cluster，需要关注的指标包括input,ops,slow commands,hit,miss等 eos使用的redis包括: - zeus_eos_redis_cache: - 端口: 8604 - 作用: db_cache, patch_cache - eos_zeus_redis_cache: - 端口: 8125 - 作用: api_cache - eos_zeus_other_redis_cache: - 端口: 8147 - 作用: lock_param, rst_number_cache 由于redis的网络流程为: client =&gt; goproxy =&gt; corvus，redis的性能排查应该是从上往下逐级进行, corvus对应的监控地址为: esm.corvus.cluster rmq rabbitmq监控地址: system-monitor-rabbitmq-queue，需要关注的指标包括ready, publish, ack情况等 dal &amp; db dal和db的监控可以使用etrace，对应地址如下: etrace dal eos对应的group包括: - eos_mobile_eleme-zeus_eos_group - eos_items_eleme-zeus_eos_group - eos_eleme-zeus_eos_group - eos_record_eleme-zeus_eos_group 同时DAL会关注dal相关指标: dal性能指标 grafana切换到dal，对应的dal-proxy服务器性能指标 DBA会关注对应的DB服务器性能指标，慢SQL，lock等 应用服务器 应用服务器的监控在: system.monitor.all，主要关注服务器的CPU Util,Memory,Network和IO等 EOS对应的集群分布为: - 外卖平台: sync-01, sync-02 - 新支付: sync-01 - 商户端: sync-03 - misc: sync-04 - 异步task: async - script,txdaemon: cron 更详细的TCP监控在system.monitor.net.tcp，可以在这里看tcp的连接情况 性能分析的推荐步骤性能分析的一般步骤为根据调用链路逐级住下，流程为: 接口 =&gt; 中间件 =&gt; 基础服务 =&gt; 操作系统 接口性能分析时需要关注代码逻辑和接口依赖 代码的性能分析可以参考: 性能调优攻略，以下为Python的代码性能优化参考 Python profile Python 性能分析入门指南 Python Profile 工具性能分析 Python 火焰图 白话火焰图 开源项目之调试python应用生成性能cpu火焰图 接口依赖包括其他SOA服务依赖，基础服务依赖等，可以通过etrace观察调用链路分析瓶颈点 中间件 和 基础服务 的性能主要通过对应的指标监控，观察对应的cpu,memory,Network,IO,TCP等 操作系统级别的性能分析可以参考Linux Performance]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[AB Test]]></title>
      <url>%2F2016%2F09%2F05%2Fab-testing%2F</url>
      <content type="text"><![CDATA[基本概念关于A/B测试所谓A/B测试，简单来说，就是为同一个目标制定两个方案。让一部分流量使用A方案，另一部分流量使用B方案。并对比两个方案的最终运营数据，看哪个方案更符合设计目标。 A/B测试的大致流程如下: 从图中可以看出A/B测试的四个关键角色: 客户端(Client) 服务器(Server) 数据层(Data) 数据仓库(Data Warehouse) 以及三种访问形式: 无A/B测试的普通访问流程(Non AB test) 基于后端的A/B测试访问流程(Back-end AB test) 基于前端的A/B测试访问流程(Front-end AB test) 关键技术A/B Test的关键在于”分流”。从上图中我们可以看到，分流可以在客户端做，也可以在服务器端做。由于PTS部门项目均位于服务层，所以我们选择在SOA层(服务端)进行分流 A/B Testing &amp; 灰度分布 &amp; 多变量测试 AB test是一种灰度发布方式，比较注重两种方案之间的测试比较。重点是在几种方案中选择最优方案 灰度测试一般是在已有产品功能升级上的测试比较。是对某一产品的发布逐步扩大使用群体范围，也叫灰度放量 多变量测试(Multivariate Testing)，和A/B Test的区别在于多变量测试涉及到多种场景的比较，其中的变量有多个，而A/B Test通常只有一个变量。 功能模块设计及实现分流模块分流开始于Dispatcher(请求入口)，分流粒度为接口级别，使用装饰器将满足特定条件的请求 从被装饰的接口(A)分流至新的接口(B) 或者使用不同参数请求原接口 工作流程如下: 请求 =&gt; 解析分流规则 =&gt; 分流 规则管理模块用于对分流维度和规则进行管理和解析。 分流维度 city_id rst_id user_id order_id 分流规则 范围分流(range) 百分比分流(percent) 特定规则分流(based on split function) 特定值分流(huskar configs) 分流规则解析模块分流规则体现在装饰器的参数中。解析模块用于对分流规则进行解析，将符合条件的请求分流 统计及展示模块暂不考虑统计模块及展示模块的设计，运营数据的对比暂时由开发拉取数据进行分析（如果有需要的话，二期吧。。。） 使用方法@split(func_name, func_get_element, rule, value, [*args, **kwargs]) func_name: 分流函数名 func_get_element: 获取分流维度的函数 分流维度可能包含以下方面: city_id rst_id user_id order_id order_mode is_book … 此处定义函数表示如何从原接口参数中计算出分流的维度 rule: 分流规则 range percent function huskar value: 特定分流规则对应值，示例如下 range: 1 - 100 percent: 20 function: 自定义function，返回值为True的请求将被分流 huskar: huskar配置中的值 *args, **kwargs: 请求参数 请求的新参数 注意事项 A/B Test分流粒度为接口级别，分流结束后需要将流量导流至最终选择的接口]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[machine-learning-tutorial]]></title>
      <url>%2F2016%2F08%2F30%2Fmachine-learning-tutorial%2F</url>
      <content type="text"><![CDATA[Overview定义机器学习研究的是计算机怎样模拟人类的学习行为，以获取新的知识或技能，并重新组织已有的知识结构使之不断改善自身。通过机器学习算法，计算机从数据中自动分析获得规律(模型)，并利用规律(模型)对未知数据进行预测。 运用分类问题根据数据样本上抽取出的特征，判定其属于有限个类别中的哪一个，如 垃圾邮件识别 车牌识别 回归问题根据数据样本上抽取出的特征，预测一个连续值的结果 餐厅出餐时间预测 聚类问题根据数据样本上抽取出的特征，让相近/相关的样本聚集在一起。比如： 用户群体划分 用户画像 Learning StyleSupervised Learning 这类问题中，给定的训练样本中，每个样本的输入x都对应一个确定的结果y，我们需要训练出一个模型(数学上看是一个x→y的映射关系f)，在未知的样本x′给定后，我们能对结果y′做出预测。 这里的预测结果如果是离散值(很多时候是类别类型，比如邮件分类问题中的垃圾邮件/普通邮件，比如用户会/不会购买某商品)，那么我们把它叫做分类问题(classification problem)；如果预测结果是连续值(比如房价，股票价格等等)，那么我们把它叫做回归问题(regression problem)。 有一系列的机器学习算法是用以解决监督学习问题的，比如最经典的用于分类问题的朴素贝叶斯、逻辑回归、支持向量机等等；比如说用于回归问题的线性回归等等。 Unsupervised Learning 有另外一类问题，给我们的样本并没有给出『标签/标准答案』，就是一系列的样本。而我们需要做的事情是，在一些样本中抽取出通用的规则。这叫做『无监督学习』。包括关联规则和聚类算法在内的一系列机器学习算法都属于这个范畴。 Semi-Supervised Learning 这类问题给出的训练数据，有一部分有标签，有一部分没有标签。我们想学习出数据组织结构的同时，也能做相应的预测。此类问题相对应的机器学习算法有自训练(Self-Training)、直推学习(Transductive Learning)、生成式模型(Generative Model)等。 Reinforcement Learning 在这种学习模式下，输入数据作为对模型的反馈，不像监督模型那样，输入数据仅仅是作为一个检查模型对错的方式，在强化学习下，输入数据直接反馈到模型，模型必须对此立刻作出调整。常见的应用场景包括动态系统以及机器人控制等。常见算法包括Q-Learning以及时间差学习（Temporal difference learning）。 Algorithms(Grouped By Similarity)回归算法(Regression Algorithms) 回归算法是一种通过最小化预测值与实际结果值之间的差距，而得到输入特征之间的最佳组合方式的一类算法。对于连续值预测有线性回归等，而对于离散值/类别预测，我们也可以把逻辑回归等也视作回归算法的一种，常见的回归算法如下： Linear Regression(回归问题) Logistic Regression(分类问题) 基于实例的算法(Instance-based Algorithms) 最后建成的模型，对原始数据样本实例依旧有很强的依赖性。这类算法在做预测决策时，一般都是使用某类相似度准则，去比对待预测的样本和原始样本的相近度，再给出相应的预测结果。常见的基于实例的算法有： k-Nearest Neighbour (kNN)(分类问题) 决策树类算法(Decision Tree Algorithms) 决策树类算法，会基于原始数据特征，构建一颗包含很多决策路径的树。预测阶段选择路径进行决策。常见的决策树算法包括： Conditional Decision Trees(分类问题) 贝叶斯类算法(Bayesian Algorithms) 指的是在分类和回归问题中，隐含使用了贝叶斯原理的算法。包括： Naive Bayes(分类问题) 聚类算法(Clustering Algorithms) 把输入样本聚成围绕一些中心的『数据团』，以发现数据分布结构的一些规律。常用的聚类算法包括： k-Means(聚类问题) 关联规则算法(Association Rule Learning Algorithms) 关联规则算法是这样一类算法：它试图抽取出，最能解释观察到的训练样本之间关联关系的规则，也就是获取一个事件和其他事件之间依赖或关联的知识，常见的关联规则算法有： Apriori algorithm Eclat algorithm Workflow业务需求抽象成数学问题明确我们可以获得什么样的数据，目标是一个分类还是回归或者是聚类的问题。需要在理解业务的问题上选择合适的算法模型 获取数据数据的来源；数据要有代表性，否则必然会过拟合；数据的量级以及降维等 特征预处理与特征选择特征预处理、数据清洗是很关键的步骤，往往能够使得算法的效果和性能得到显著提高。常用的方法有归一化、离散化、因子化、缺失值处理、去除共线性等。 筛选出显著特征、摒弃非显著特征，需要机器学习工程师反复理解业务。这对很多结果有决定性的影响。这需要运用特征有效性分析的相关技术，如相关系数、卡方检验、平均互信息、条件熵、后验概率、逻辑回归权重等方法。 训练模型与调优在训练的过程中调整算法的参数，使得结果变得更加优良。 模型诊断 过拟合、欠拟合判断是模型诊断中至关重要的一步。常见的方法如交叉验证，绘制学习曲线等。过拟合的基本调优思路是增加数据量，降低模型复杂度。欠拟合的基本调优思路是提高特征数量和质量，增加模型复杂度。 误差分析 也是机器学习至关重要的步骤。通过观察误差样本，全面分析误差产生误差的原因：是参数的问题还是算法选择的问题，是特征的问题还是数据本身的问题。 诊断后的模型需要进行调优，调优后的新模型需要重新进行诊断，这是一个反复迭代不断逼近的过程，需要不断地尝试， 进而达到最优状态。 欠拟合 欠拟合的原因：模型复杂度过低，不能很好的拟合所有的数据，训练误差大； 避免欠拟合：增加模型复杂度，如采用高阶模型（预测）或者引入更多特征（分类）等。 过拟合 过拟合的原因：模型复杂度过高，训练数据过少，训练误差小，测试误差大； 避免过拟合：降低模型复杂度，如加上正则惩罚项，如L1，L2，增加训练数据等。 合适的拟合 模型融合单个模型的结果不够理想，如果想得到更好的结果，需要把很多单个模型的结果融合在一起。可以想像成“再次的机器学习过程”。 上线运行模型在线上运行的效果直接决定模型的成败。 不单纯包括其准确程度、误差等情况，还包括其运行的速度(时间复杂度)、资源消耗程度（空间复杂度）、稳定性是否可接受。 Machine learning in pythonnumpy数组运算 scikit-learnscikit-learn作为一个丰富的Python机器学习库，实现了绝大多数机器学习的算法。这是针对实际应用场景的各种条件限制，对scikit-learn里完成的算法构建的一颗决策树，每一组条件都是对应一条路径，能找到相对较为合适的一些解决方法 根据问题是有/无监督学习和连续值/离散值预测，分成了分类、聚类、回归和降维四个方法类，每个类里根据具体情况的不同，又有不同的处理方法。 matplotlib非常方便的数据可视化工具 Demo一元线性回归预测披萨价格 已知的训练样本如下: 训练样本 直径（英寸） 价格（美元） 1 6 7 2 8 9 3 10 13 4 14 17.5 5 18 18 披萨价格与直径的图示如下 123456789101112import matplotlib.pyplot as pltdef runplt(): plt.figure() plt.axis([0, 25, 0, 25]) plt.grid(True) return plt plt = runplt()X = [[6], [8], [10], [14], [18]]y = [[7], [9], [13], [17.5], [18]]plt.plot(X, y, &apos;k.&apos;)plt.show() 能够看出，匹萨价格与其直径正相关。使用scikit-learn构造一元线性回归模型 123456789from sklearn.linear_model import LinearRegression# 创建并拟合模型model = LinearRegression() model.fit(X, y) # 预测其他直径披萨的价格X2 = [[0], [10], [14], [25]]y2 = model.predict(X2)plt.plot(X2, y2, &apos;g-&apos;)plt.show() 可以看出拟合出的披萨价格和直径的模型。]]></content>
    </entry>

    
  
  
</search>
